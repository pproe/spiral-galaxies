{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation of Spiral Galaxies\n",
    "\n",
    "This notebook provides a detailed insight into the process that goes into the segmentation of spiral arms from images of spiral galaxies. This notebook accompanies the final year research project I completed for my Masters Degree in Professional Engineering (Software) at University of WA. The dataset used for this notebook is adapted from images retrieved from the 2nd public data release from the HSC data archive system, which is operated by Subaru Telescope and Astronomy Data Center at National Astronomical Observatory of Japan and classification of spiral galaxies from this dataset was achieved by [Tadaki et al.](https://arxiv.org/pdf/2006.13544.pdf) and all image content is a product of their work. You can register to access the HSC Data [here](https://hsc-release.mtk.nao.ac.jp/doc/index.php/data-access__pdr3/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Install Dependencies\n",
    "\n",
    "Here we will run the imports for packages that are used commonly throughout the notebook. Any other required packages will be imported within the code cell that they are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list\n",
    "#!pip install --upgrade --user tensorflow==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 16:34:02.837482: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-06 16:34:10.820024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-06 16:34:10.821184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-04-06 16:34:10.821212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Data Pre-Processing\n",
    "\n",
    "This section covers the functionality used to process the data prior to it being used in training the segmentation model. These functions take the images from the dataset (in the format of `.jpg` and `.tif` files) to a data format that is usable by the Tensorflow Keras API. To achieve a concise pipeline, a Keras Sequence class is used to load and vectorize the data before training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Location of Data and Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '../data/images/'\n",
    "masks_dir = '../data/masks/'\n",
    "img_size = (64, 64)\n",
    "\n",
    "val_split = 16 # % of total dataset to be used for validation\n",
    "test_split = 16 # % of total dataset to be used for testing\n",
    "val_batch_size = 1 # batch size per step\n",
    "test_batch_size = 1\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Split Into Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 16:34:19.637581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-06 16:34:20.351339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-06 16:34:20.351635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-06 16:34:20.381818: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-06 16:34:20.400437: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-06 16:34:20.400719: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-06 16:34:20.400917: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-06 16:34:25.858610: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-06 16:34:25.860054: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-06 16:34:25.860433: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-06 16:34:25.861535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15389 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "images_ds = tf.keras.utils.image_dataset_from_directory(images_dir, \n",
    "                                         labels=None, \n",
    "                                         color_mode='grayscale', \n",
    "                                         shuffle=False, \n",
    "                                         image_size=img_size, \n",
    "                                         batch_size=None)\n",
    "\n",
    "masks_ds = tf.keras.utils.image_dataset_from_directory(masks_dir, \n",
    "                                        labels=None, \n",
    "                                        color_mode='grayscale', \n",
    "                                        shuffle=False, \n",
    "                                        image_size=img_size, \n",
    "                                        batch_size=None)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((images_ds, masks_ds))\n",
    "\n",
    "train_ds, test_ds = tf.keras.utils.split_dataset(dataset, \n",
    "                                 right_size=test_split/100, \n",
    "                                 shuffle=False)\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.split_dataset(train_ds, \n",
    "                                 right_size=val_split/(100-test_split), \n",
    "                                 shuffle=False)\n",
    "\n",
    "val_ds = val_ds.batch(val_batch_size)\n",
    "test_ds = test_ds.batch(test_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Data Augmentation Pipeline\n",
    "\n",
    "Using in-built Keras preprocessing sequential layers, here we build a pipeline that can be used to augment the training images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, mask):\n",
    "    \n",
    "    aug_model = keras.Sequential(\n",
    "        layers = [\n",
    "            layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "            layers.RandomRotation(0.8, fill_mode=\"constant\", interpolation='bilinear', fill_value=0),\n",
    "            layers.RandomTranslation(0.2,0.2, fill_mode=\"constant\", interpolation='bilinear', fill_value=0),\n",
    "            #layers.RandomZoom((-0.01, 0.01),(-0.01, 0.01),interpolation='nearest'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    image_mask = tf.concat([image, mask], -1)\n",
    "    image_mask = aug_model(image_mask)\n",
    "    \n",
    "    image = image_mask[:,:,:,0]\n",
    "    mask = image_mask[:,:,:,1]\n",
    "    \n",
    "    image = tf.reshape(image, [-1, img_size[0], img_size[1], 1])\n",
    "    mask = tf.reshape(mask, [-1, img_size[0], img_size[1], 1])\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "aug_dataset = (\n",
    "\ttrain_ds\n",
    "    .repeat()\n",
    "    .batch(batch_size)\n",
    "    .map(lambda img,msk: augment(img, msk))\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate Data is Loaded Correctly\n",
    "\n",
    "The following plot should correctly display 4 examples from the augmented dataset of overlayed image segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-06 16:36:06.879087: I tensorflow/core/grappler/optimizers/data/replicate_on_split.cc:32] Running replicate on split optimization\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoMAAAKACAYAAADn+nIgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB35UlEQVR4nO3daZNkx3XmeY8tIzNyrw07CZISRUqiSIlST09324yNzbv5tPMR2kzdo6W5iRQJkAABEEuh1twjIyJjufOChu46zzlI97rMAirT/79X9MBd/K7pjHr8RKdpmiYBAACgSt2vuwMAAAD4+jAYBAAAqBiDQQAAgIoxGAQAAKgYg0EAAICKMRgEAACoGINBAACAivXbrrhardL9+/fT9vZ26nQ6V9knAJVrmiadnp6m119/PXW7N/f/s/IeBfCiPM97tPVg8P79++mtt95quzoAZH3yySfpzTff/Lq78cLwHgXwopW8R1sPBre3t9uu+tLo9Xqmvba25paJPlOr1cq09Udd+n1/mnWZ4XBo2tG3BBcXF5e2U0ppOp2a9nK5DHp8Od03P1KDr8tNeM9c5qYfH4CvX8l7pvVg8Cb8k4YeQ3RMJceZW6ZkG/oVbrROyTJXcV1KtsEAEV+Fm/CeucxNPz4AX7+iMchX0A8AAAC8pFp/M3gTLBaLS9uR6J98Z7OZaW9sbJj27u6uWyf3z8/j8dh9pv8cvb6+7pbZ2toy7bOzs+x2r+JbvtFo5D7TbzInk4lpt/knbAAAcLX4ZhAAAKBiDAYBAAAqxmAQAACgYgwGAQAAKlb1BJKSXzbQSRtRbb/BYGDaOjnk4ODAraMTUXZ2di7dZkp+kobWFEwppePjY9PWyS0lk0X0mEtE69z08jMl5X9KJsnoOtF9qee3zTUqKUWk1+ymX0MAAN8MAgAAVI3BIAAAQMUYDAIAAFSsqsygZvn094Dn87lbRzNfUYZK83/6m8e3b99262gmUNeJ6DJRbkyPQdttsmaRqPh2ri83rch0dC+UHKNex5Lfgm6T3dNrVLJdMoIAUB++GQQAAKgYg0EAAICKMRgEAACoWFWZQa0RqJm2krpx0TJKc1dRvi6XGYz2o/2fTCZuGf3sKnJ6Uf81f7lYLNwy0Wd/qui8aF+iY9bP9JiiLGVunZLMYNTfXPazzTWL9qPbKcmlAgDqwzeDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFCxqiaQqJKJHuvr66ZdMoGhZKLBZm/LtHs9Oy4/nZ+6dabTabYvOkmgZJKMrlNSeFi3G60zGo1MWyc0zGaz7H5UtB+dWBPRAuN6zfTcpuT7qxM9dHJR9Fk0MUWvgd5jUV90nY2NDdMuKZge3d/aX530E53bqypcDgB4OfDNIAAAQMUYDAIAAFSMwSAAAEDFqs4MqigLpRk1zZ6l5DNf+903TfuN4WO3zt4rZ6Y9PXhd9mszYSml9HT11H2mtL+aNdvZ2XHraAHsszPpW5BhUyUFu5Xm9qJ1NMMWFbLWbGJ0HTWfqOdJr2HUFz0P0X70XEbHuLm5eWn75OTEraOZQG3rflNKaW9vz7Sj/J8WKddjKsmPAgCuN74ZBAAAqBiDQQAAgIoxGAQAAKgYg0EAAICKMYHkGVqkNyUfsI8mGmh4fzC0kxx2dmyB6ZRS6t+zYf7+8APT3v/ou26dp1t2O9q3lPwEC50AEB2jrqMTJaJJMyqanKATUdTWVnBepDCyHmPUf/1MCzKnlJ/Ysb297dbRc6fnJZrMopNBokk0ueLV0XlRuYLYkWiST67wejQBpuQ8AACuD74ZBAAAqBiDQQAAgIoxGAQAAKgYmcEMzWZFOT3No+3275r2dPCOW6ff2OzhoGezWRcX526d3txerqggcK5I8Pm5365m1jQ3FuXe9LyUFCfWzJoWTk7J5890nShPp/uO8nNagFmzn9Ex6nnQfUf5xVzfov7pMtF50aLZel6ivkQ5TtXr9Uxbz3+0jZLjBvD89HmMPtN3VfS+089ybYBvBgEAACrGYBAAAKBiDAYBAAAqRmbwOY3HY/eZZjpWG49Mu+tLtaXFwubCzv9gM2BPzv2lOVoc2u0GOTfNtWkGLFpHa8lpnkTryqXkj/nOnTtumVyuLeqLfqb7iWoeluQVtfagZgajGny5vkXrtMnm6HaiY9TsnuYKj46O3Dp6XqL6i7odaggC7ehzrO0oD6h58+jZ1/dzSV5Y3zv6nEdZYH3WS7KIuDn4ZhAAAKBiDAYBAAAqxmAQAACgYgwGAQAAKsYEkmdokeGUfHhX2yn50O98sWcXmB9ktzvt2YDvcuEnJ2jh4SgErIHk/f190y6ZKKGTCKLzEn2WW2Z7e9u0o3NZ0j9VMjFF95Ur5FrSl+i/b/TtvRCFu+fJfqbnSSe3pOQng+g1igpVlxzj48ePTZsJI6hN9Bzrs6PLRM+Svnv1uY7emduDHdNeG/plln07aWM92ffDauUn0F2sJrKM3cbF3P/tmFzYvy/69yal/ES2ksl8eDnxzSAAAEDFGAwCAABUjMEgAABAxarODJZktbRQrxZ1TimlN9Z/ZNp3Ru+a9mDHFxs9PT017bOpzWIsZ/nsRVTEVDNfUe5D5Qoll+Qko2VyP6ge5elyWZ3omHXfmt2JPuvNpWh29wdune3135n2aMv2d7gV/Kj8wPb36MFtt8z54nXTXvbtvXCUPnLr6HXVbM7e3p5bR0XnezQambbeL9G5LClKDrys9B0SFWPXvwX6Ltvu7bp1Br1Nu43eLdMe9vzfjluj90x7tOm/n2lWkleU104U01vMh7KMXeho/B/dOg/nPzXts4tzt4y+H7QdZZc1Z0jh6pcT3wwCAABUjMEgAABAxRgMAgAAVKzqzGAJzUNF2bjByGZOekObz1j0fY5i0LNZrK0du93tE58vOW1sJiXKZ4zHY9OeTGy9qSg3pvk/zZ9FdbhKcoWayTw/txmUqKad9iXqr9J8T5RzW+vZvuz1v2/ad/d+7dbZ/rZdZ0320x/4x6dJ9toP7x26ZVZLW3dy9cieu8Mzn+d5vPiFaWuGKcpS6r0QncudHVvnTK9rdI00J6T3B7XG8HXRd46+T1Ly7yrNzaaU0hvDH5v2es++4zfXbC48pZQ2tuzfit7657Zva0HeWd77/SAzmJby/pXNrBqfwWvm9hlcruyz33n/V26di/O37Xb7H7ll9N2q794oo65/Q7UdvWN4h3z1+GYQAACgYgwGAQAAKsZgEAAAoGIMBgEAACpW9QQSDa5GxXO1yHQUNm4GdpJGI4Hf0cgXNe1LUdDp5A3THg/fd+tooWSdIJCSD/BqoDoK5upEFJ0QEE0O0YkG0Y+w66QGPXfRj73rvrS/0USJ6DM16uyb9r0dW1B6+9v+GNe27DFFE1PUYmGD2r0Nf4xDOVe9fQm9f+bD3euP/tq0n3Q/te2ODatHogkkeg+V/PC8nm+9jiWTfoDnFb1jcj8cEBWU/rORnaC1tfGeW2Zr9/emPdy193x/5J/r3qbdV0e62wned9HkvOfVDeZaLAf2/dyVWSf9gX9GB337fl7r+XeiPvv6NzR6R+okHr1mOskxJQpVfx34ZhAAAKBiDAYBAAAqxmAQAACgYlVnBktsbtpCz7ub226ZW8M7pj26JVmLjs0/pJTSomezfRezY9M+ntp2Sj7PFWUcNeOlGbySHxI/Ozszbc1NpuSzIWExbllG8yVRZlAzP5pRebP3926d3e2fm/b2XV9odrgrx70mP+Te95kUzbZof6Mci1/H5xn7ff3M5oY6b/k8z+2RLXK79qm9zv2VLaKdUkofX/yb+0zpMej5jvKYer9cRe4JdYmeff1M3yn6boiW0fa31/+DW+fua7bA/MbdoEj9pjzHw6v43qRtIWW7nj6zq5Xf7nJp37WLp/a/j8ffduuMlzaHHH1VpM+6vuOj66rraKa4JJccFbOOilWjPb4ZBAAAqBiDQQAAgIoxGAQAAKgYg0EAAICKVT2BRAuS7u7uZpdZBcPnzfV37DqvyKSNjg/ITha20OZs9gfTXl/4SRunU1tYWIP8KfkCn1roOSrCqgFenQQRTSLQZaIJJLllorCxrqPtrYGfAHP7LXuu1l/1t3Wna0PMOrGj2/WTIKJg9rN6vXwIPshGp9Xq8qLM3bWg/3ftOmuH9tr3zvz9otctKgir94OGu6PC5ufn56ZNkBs5ei9G76HcZJBXh3/p1rk1lB8F2PjQtLdu24lXKaW08aZ9Rw7Wo4L5+hzrJA7/YOtz0PhXldez27n43G/34sROGJG5IfF7qmPXOTv7jmkfLg/cKmedU9PuNlfzXZFOINF7Qf9mpZT/O5CSn1Si5z8qfh9NVsEf8c0gAABAxRgMAgAAVIzBIAAAQMWqzgzmfnQ7Jf8j2lHh08XiTdNeTe+b9qzrs32n79pMx7Tzd6Y979tCyin5PFpJ/k+LTEcFpDWzofuJMoP6WcmPyLdZx/0Q/do9t8764JFpb4x8f6Piz89qmuf/IfSo6HSuiHNKKXU69jNdJyri3JVfo19/wy5za/4Tt87FpzZjtez+2i0z7thMYJvC2ooMYd2iLHBJAWn9TDOCr21/7NbZedPei4ORtLeCd0xBAelcRvDi0N/jM/ns9JE9nvnybbdOr2uze+cXr7hlJiv7AwSLlRZg9s9oI+H2i/SZaZ81h26dEvpu0nb0vsiJ3id6D0XL6D2lGcKSzKDm7mt+d/HNIAAAQMUYDAIAAFSMwSAAAEDFqs4Mar00zQemlNL+/r5p76VvuWV6/Ye2PZA6Sv2gBt/A5hm09Nzkwv8wt+YoovyfZjh0nadP5RfLA3fu3DHtnZ0dt4zWrCupM1hSX0o/0/101vx5WZ79wLS7h793y2xItqgk66KZE13mqvIlel5y9Q1TSqkjp27jGz6beKf/K9Oevfsdt8yDRvKtkruJMo963DXnbODfMdG7QOudRpnBNzb+2rRf3/3UtHe/49dZ29V6od1L25HFIsqW2Wd9/L5d5uDJ99w647ld53xp68LOVr7mYbexD/Js+albZry0f6c09xZl46Lc8fO6qpp8V9GXaBsl9XCVHpO+787Oztw6tbzf+GYQAACgYgwGAQAAKsZgEAAAoGIMBgEAACpW9QQSnRCwubnpltne3jbtnTVfFHS489i0BzsyOeEi+CH0oQRiJaMahYJ1MkWu+G+0TLRdDchqEDcKYesybSaQlBQS1cLay4Evljrt3zLtwen/6ZbZevxvpr3+tv3vS/3195TSfH75RIko1KxFvqNzlyvM2utFgWstkC6TTlIQgt+0/e12nrhldMKOBvuja6T9n06nQX9RC30vRRPb9N2qBaVTSumtfVsYefc7Mplsxz9LWkxeH8loEoROGFnp7L2U0ul79jl+8vhHtr0ICrivTk07NwHtj8scSd/8e0g/0+2UFHrWd1V8Xux+Soo263ajSRy5vwPRezQ3ETJapqQvuW1E518nmrYprH0d8M0gAABAxRgMAgAAVIzBIAAAQMWqzgyqKCOhGbDz2dgtczGxywyW8iPhBz5jMDmyxatn65+Y9mrs19GCmJqniz7T3ESU59HMj+bGonxJSWZQPyvJDOq+c+2UUuqs2eu2lELKKaU0SHa9jXWbFVmuosKitgh5SfFRPaYoX3IVmZNeryttn48ZrNu+bO34zOCrsx+ZdrP+c9N+fGLzsCn5H3dHXTRnlcudppTS61JQ+s29z9wyu9+x74u1Xc2a5b+70GdrfuSftYtj+744P5i7ZQ6Of2Tbq3dMW/OB0b61Hf190c9KMoMlRd/b5Ar1PR+tk8sMtikOHb272uTWSzKCubxitI2rKJp9HfDNIAAAQMUYDAIAAFSMwSAAAEDFbmxmMPp3fq11pVm5KHsxaCTv0AT5hsHluYlVx2/34MDm/w66UqtQ+pZSSpPJxH2mNL+juY8op6fnpSSvof2LltG+6DJRtkgzjZqBjNbRvkQRj6fLV027//6B3e43/Tp6rrrdfD6mpG6V1i9smny+R8+d5vaiPJLWYNv8ts9G7Rz/wrQPT+15Wiw+d+vU8sPtiO/x0Whk2vr+eGP0A7eOZgRvfddnjAc7+t7JZ8C0RqBmBI8+8Ns4Orc1DmerY7fMuHnXtoOMYE5JrTx9btvk00pqBr6o2ni676gv+q4qyemV1CJU+negpPZtSa6TzCAAAABuPAaDAAAAFWMwCAAAUDEGgwAAABW7sRNIoiDrbDYzbQ2pRpM29LO7+++4ZdbfujzsunnbF4fe3bWh2qMLu0xUHFoDyFHwVn9UW/sSFm2WZfSYdSJISj6cG4V1dV8aPI+2q2F0XSfqv4aCo2uvxcPTxVumuZp+4NZJckh6vqOw8XQ6lWXywW3tWxz2lklJK79vpRNT5k1QLLpng+aDzo5pR4XN9bpp/09OTtw6FKq+nqJnVN9NOmHkG7d80fdb37XP7XDPv2tzRaUvnvjnYn5un/Xj+/YZfTS569Y5WtnC6ovGP0urZPcVTf5QukxJEeeSyQm5ws7RNrQvOqEkene9qEkmSs9LNCEt6l+Obse981O+AHZJAe+bim8GAQAAKsZgEAAAoGIMBgEAACp2YzODEc0QnJ7aQqK7u7tune66FkL1p6yZSwYiyQ+hvx8UBe1/37QH6Wf2vzc+p6C5vJKsSJtcpObyopyeZomibFmuOK22U/J5JF0myjDl8jEp+YLdHSlC3Zn/wa2jmUGNIkZZEs0Inp+P3TLav5LCrcqv45cpKTi+s2/P9+nYZgY7M3+PnZ3Zgul6bilKfX3pOyZ6Rl/f+GvTfmvfFpTe/U6QM5WMYHQv6uts+om9qQ8ffNetczaz2z2bPzDt0+Sf66XkAaP3aJTHznk1/Z1pr3VtfjuKwa2kmPViLci6z+179HBmj/Hp0ued9dnXZzJ6RjVTH2Xuviol70BVUmhbl8kVoW7bl+uIbwYBAAAqxmAQAACgYgwGAQAAKsZgEAAAoGI3ZgKJBkGjgLIWstSJE9EEktvrr8k2Tt0yS62n27P7mc+CIsgrO7Gg6UqIOQgb64SMkoKlGgiPJoPoMnpeooLSbSaQ6OSQnR07WSH6TAPs0QQYva5a+DklX/R4vpLJONOgCOuGFG2e222cfeb3c/KZ3Az+1KW0I8Vo5WJ31/111WutE1UWi3zYO3omBlt23/2ODVhHxXZLisaivWjyQq7geZsivSn5+0qf9TsbdqJVSim9sWsnjNz6rn3ON275m94X+/X3lYb3Vxf2Ppss/DvmcfMT076Q+9e9V1NK/Y7tS8l7VL3R+3v32f6enQTY1+c8mnDW6MSO4D0kExS3PrHP+tbkf3PrnC4+NO3j5VPZj39m9R6LCsXnJqK8TJMtrmoyiN4fL9MxXiW+GQQAAKgYg0EAAICKMRgEAACo2I3JDOq/68dFTe0yUf5MbVy8Yrdx55FbZt632+0upfDzwI+5NwY2G9db2bxGSUHpEnqM0TZyhaqjc1lSnFYzgvv7+6Z969Ytt8729rZpa8YxymtoRlCLp6bk8yOzpS2U3J3mC5TOjmxW5/gTn7u5f/S2aZ9JgdiUUlpLd017b/gb0173pzINJM7av6PX0d/Leq7m8+AH4fs2F9SsTkw7KvKt10jPU5TZLPHsfdY0Tesc3E2kz6TPkLY7V/ps6/PWHfrt6j0x3NDMcT4zGGlsLfM0Odkz7fNks4op+Uxgt7HPRfS+03NXkhl8rWMLSt++9XO3zPqb9ribvhaGj4rU9wuWsZ8Nt+w6e0fvu3Umh/a6PT7+32176fs/69v35jT4+6jPuuYKo5yh3ptfZ+ZO961/F6J7Qe/dqP8vc3ayFN8MAgAAVIzBIAAAQMUYDAIAAFTs2mYG9d/29d/+ox/Z1pyb5nCirNlyaP/tP6oBpjmP+YFtn5/6+oVni/t2P00+86P5lyiHo8toO6oZqDkhzQRFtQk1IxhlBjVbtre3Z9qaIYzWKblG5+fn2WX0s/PpJ6Z9EdQZXD6199DJgb0XTmY/dOscp3+17YWvS9lZ2OzTycIe88bC11/cPfmGae9PbeZn45s+39Pva87M/3+/6YbN9/W6j017reO3q8+WXtfo/B8dHZl2lKl59rPrmLm5KiU5NxW9lzSrFS2jz7a23xjarFxKKW3f+Z1pD0b2HoneS1pXcDnx2bjTj+xnB/JcTLsfuXW6KZ8RdOsULPN658emfeuWrSG4/oZ/j2p9UP2bFN3TJcvodezfkZznbX8uR2O7ztoH75j27XP/XJ+O/9q0n8x8RvNw+bnti1zr6Nzq+yD62/x10fNfcm9Ez+JNqEXIN4MAAAAVYzAIAABQMQaDAAAAFWMwCAAAULEbM4FEg6xRQWkNUOtkild6NkCbUkrDtX827cWO325nZT9rlnY/51P/Y+/Hy3837encFuuMwt4lhVv1vGggNipOq2FXnUAyGtkfok8ppY0N+6PxJUWndXKItqN9acA3KmjsJofIhJKUUppMbJHps9lD076QgrcppXQxtcd0PrXn6bz5le/L0oajwyCxFCm/6Ntjarr+Gt3qfks+sdtdLnyIfCWTkqbTiVtGt9PrHZv2YOkn+axWtpD2wcGBaWsB1lIUmf6jkokGuec8pfz7LiU/YUTfm2t9fy2Hm/Y91F+z+9HJIlF/o788TWP7t+zYh1ILTKeUUr+bn8CgdBmdLJJSSvv7PzXtoUwY6azlr1H0Ds8pmUCi+9F2Sin1+9KX79q+XEx8ceito/dMe/3TV9wyg5k9D097n5p2SQFv7e/L9NxH51LfZ9Ex6rVu83f368Y3gwAAABVjMAgAAFAxBoMAAAAVu7aZQf23ff13fc29peQzM5rB66z5PFq3a7MAg6HPDK6t2X3NN2xfeh2fYetIQeC9zT373wuyF1GGUNfTY9asX0op7e7aotia9YvOZZvC1JoHjDJMSq9rlBnUPGBU9Hg8Hpv2ydjmkc6n/hrpdiaSuYt+lF0/i7Ii7r4rKFg66D4x7a5ENBdLX8i15Afi9bNuz7b7K18AO/dj71HuBuWie0YzSJrtKylAH+Wodb3X+rbI9N6ezZGllNLwtr35dLvRu8tlf//g78Xx/Aemvej80va1lz/Gkizlax17jPv7P3PLDF+3x9SVV2B0j0dF3e1/v/Q/p5TiZ9S/H7QvQcF8uYc6W7ZvvXXf1/6mfYd0eo98Xz6+J31707SfJJsh/GN/L39fRO/0l+kdUpLt02VycxpSymdBv2p8MwgAAFAxBoMAAAAVYzAIAABQsWubGdQsSElNp1wNqln/sftsb+eWaQcl91LTyL/1b9vTurFua7ellNL2yubylr18jaqSY9Rsgmb7ovyfnhdtR9k+zR5G29UcoS4THY9mBM/ObLbv6OjIrXN8bM/v6empW0ZzhZrti2rjaWZQsy0lNQ+j/FeuDl+UuVqupCbj3C4TraM5lug66rU+Hdrc0Hyar6ml9SI1n5lSnK9ErE2dwSgPqNc2yi3dHtjM193t35j21rfseyqllPqj56+fN7elKdPZ8Q/cMqddm09cdiS/2vX9z9V3u9f1tWPvbNv6oBvf9OcuDey+XbY2+Fuiy1xVHTndl6/T59fR+6PTset0g5qNbhuv+WW6kl1OH92RJd5MSnOEJXUG9X3xddbka3Ndc/MTUvJ/P8gMAgAA4GvDYBAAAKBiDAYBAAAqxmAQAACgYi/lBJI2P3ZdEpbO/eD028M33Drrrx5q79wyGmIeDKTQ8yj4UfDZa6Z9kmzCej73RYQ1uBpN2tDj1mB5FDTPhV2jiQf6WUlftP86qSMlPwHj4ODg0nZKfgJJNIEhN/mjZB29f6KJIPpZyXXUdaIC3pORPZdbckv1g2dGr8lqFU1MsMW2tbhuL/j/i3peSibN4GrlitymlJ9ckZIvMt6TYvj9oZ8skiuSHgbsVx1p+uL3Fz17X+mEkZIi++5d3PHP0nAk78RRvhh79N7P0WLQcdF390mwnVxR96hv+rdOJ6E8//GklNL6K7Z9u/PU7ucj+3ctpZSaZD9bLu2Ekmhymb4TX/Z3Su5HMHKTV18GL38PAQAA8MIwGAQAAKgYg0EAAICKvZSZwTYFJjXHFG1DCyVrNqtpfD5mPpdc2MKPn4eSq+n15AfifZwudc9tod756hPTjnJ62t+SH57XdklxYtfXIO+g+y7J82juI8qKnJycmPbh4eGl7ZR8kWktVJ2SzwTqMlF+UXMf2l/NykXbibIummvS8xRud2D7v5hJZjYoWLpcXp5jSSmlxUT6N9PMmL+u/cnl91R0j52f22xirvA2LqfnOMwDFhTmX/YlM9qx751OwfcFJa/rbl+yfUHR437H3lfa36j/uYL53U7w/Ml+BsFfwW5Pj1vPt++/XpOS4sr6WVR4WN/Puk70vGn/SgpVqziHas9L545dZvi5fz8Plpf/8EFJ9vplzwyqkvfb111kWvHNIAAAQMUYDAIAAFSMwSAAAEDFGAwCAABU7KWcQNKGBoejyQk66UEnZPQGUlEzpdRf2aKaOlkkpXjyxLPWNvx/H4137XYbG6qNJoeUFJHNha5LCkjrvtsEt1PyAdlc4eeU/AQRLTKtE0xS8hNIdLJC9FnJRA/9TAtIRyFh3W7UX53ItL+/b9rR+R7PH5r27Nz2pbvwYWQtNBvdpzpn6mL6pmmf9n7r1tH+6zGWTDhiAsmfpmTSTq4gc0op3ev/rWmPdt+12/CvoXaW0t+gL73O5e+u6P7NvYfWu3aiXkopra3bg9oY5bfb6+nkFn+P5ybMRff8fGI/mz7yy0xP5Vnftvvpb7pVsn2LJ53k3+n6TumMbHvnlv+7O55/x7SPFvZdFv1N0vdF9Pf8ZZuAcZnr8L7jm0EAAICKMRgEAACoGINBAACAil3bzGAu1xb9G71mDG43f2nam5u/9Dvasc2m8eNnLQra7UpOb+TzMRtSeHNDfrg9yveUFGHNFZ2Ocjea2dCioFGmQ7cT5Uu0eLJmBKPi0JoRPDo6Mu3j42O3jhaULskMagYlul9ymcGoWLfel9vbPrOk96H2JbpGw+aWaXfW75t2txvkAaV/YcZmsJJlbEZ2tfDHqFlbvV+iotlRdhLt6bUtKdQf5cSGPfs8DXYkjzYoyQvn82i+aHPwfute/n5rk5G+6NrnJKWUllObYRucP3bLjF6zz3FJjlotpvbZmk/mbpmjR/bZP33yl26Z8cxmonuH9vnauuX/bvX2bLvTkSL1ff8u0PdDyXXURTa/4e/De/Nfmfb80T+Y9h8W/+TW0fNdkknHn4ZvBgEAACrGYBAAAKBiDAYBAAAqdm0zg5rfKsk7aBZLs02rxufGBiOb5VtbG7pldLuuBtVukO17dHmeTnNZKfls1s5gxy3z2voPTfvW7m9Me3PX5/82d23/m+nfmPbJms/dlGQ0NXOnNfi0PmBKPhOoy0Q5Q91ulFnT/mnGSu+naDuae4vuMc26aN+ifUd5GNXffcd+sKXH4x9lvYcWC19LcTy357PTse3+cs+tczj50LQ1jxmd/+v2Q/MvG32/aTs6v/qMDoJ7pN/9g2l3hv79pnL16MLnYscus3H61C2znWy9zWnX3ottMoOzvn9fnA9s/nZ5+C23zHBkn/XtV+3fgX5QgHEpUeXjByPbl7GvYztr7Ern6z93y5wk+07sz+w1WjyxGbyUUlo9tO+z9cFPTXvjzeBcjuw9VJIZVINNn+PbfNtek3sLmyG8ePBjt85k8N9MO8pR6z1fkpvFl+ObQQAAgIoxGAQAAKgYg0EAAICKMRgEAACo2LWdQKJhYg3uazullG6t3zHtOyMbYh7eiSad5H8sfTi0kzJcoHrPj7nXh3bCyFZ/y7Q3NmxgOaWU7vRssdTdoQ8k3733a7vMn0lx600/MWVz0+5r8Ycntt3zfdEAe8mkAZ2AcXh46NbRCSO6TlRQWieHRMVI9Zpo36IisrkfS9di1yn5EHMUwt7d3TXtqKi3Wi5tuL63stcoui/9vn3AenGq/bXbGQ79/dLMLj9GneiUUjBZi4Kxz0XPl054KgnYXywv3DKnF3bywa1H79kFbvv7V693rp1SSj0pZr32+GO3zPrie6Y979nJV9EEkty+o78Ds+GRaU/Wvu2XmdmJeFvH9m9HL3g/p55MQtv7wDQvup+4VeaN7Ut3FfytSPYZPF9JAf3l79w6F0uZkHhhj/HWJ7ZvKaU0ekuKfI/cIqnX03eIXSeayLa2Ze/dzTftMtsHR26dza4t1n/W8xOB9FozgeRPwzeDAAAAFWMwCAAAUDEGgwAAABW7tpnBXGYtKto8kwzKfP6Z3eaGzXL9kc0luILSyedS+n3bXg18Qdid121m5lsPvm/a057P4L269blp3/7zJ26Z4Z7d93DT5tGGGz6fNhjKj4Kv2XzG+uKv3DqTqc2/jNPULaMZu6OjI9PWAtMp+eLbWrRZ/3tK7YqPlhTt1c80CxcVqtZjju5D/UyzL7d7vgju2uBT0+6v2Yxpt+tzWnqutG8ppXTxxJ6ryeLvTfus+Ue3Tq5gd7QfMoJXS+/N6P7V67Ro/DKT1WPTXknt+M5VfV0gkdxu8Jent7DPl/a/5LnW7GSc8bb7WW357O98377funftPb62Y5+/lFKar+R9cWz7u5Z8lra3kPf1wi+jz5dmJ2fB34qF9OVoYYuLNxf+HZM+scXkNUOYUkq9IEdothtcI/1sbcfeZJtbD9w62+O3TPtRxy+Dq8U3gwAAABVjMAgAAFAxBoMAAAAVu7aZQaW5hChbprXkmvU90+4ufEZCMyebm5tuma0tzW/Z7axWPquz/ue2TtWdNx6Z9qDn62MNtmyeZLjl839as07rxEV1t1xtrm/YzNfmh//m1pmd/6Vpnyz+3S2j10Dr8kXXSJfR/FmU0yupM5jbTpR1iWonPquk7llUvzD+Afj/Zb1zx322devAbnfH/veo/9q/JojtLRdSv07O5YWGyAJ6vskHvni5uoMpxc+6mieb253P7LtqMfPXcrBmP4ueA0/yf/6VmOZLmw9eJrtQyfOmoudP3+nRedL3/OaerXu3ueUzg7nnIKpLenZm89kl7wvtv77/UoozpM86WH3oPlu/sHnhjZOfuWX69jS4907Ufz0PgzXb/627/vzvHt62fRv4v3WTzsR9hvb4ZhAAAKBiDAYBAAAqxmAQAACgYgwGAQAAKnZjJpCoaHKCK0g6+KZpbw/9Oru7Nqm/vb3tltHPioLbcxv6Xe7adhSW1s+i/egEkn7fB3qVDxvbwG9nPfjh+WMb3u2c+4k1Z1NbFLukCLL2pWRyiH4WBap1mZLQexSGzv33qMit0rD/7tDeY5vrwcSgDbnWckmiY9Zw9/LETzI5fGyLu346/mfT1oB7Sr4QuJ7L6BxE/cPViSYMlEzsWazsMzmf2/tsOQmKsY/sZzrBoWSix9q9oBD/pw+lv6+Y9qR56tbJFaIuKYJcUsy6ZJmS8/C82/iyz3L/Xfed20ZKKS2SnTDXLIP3vk7CzJ8Wd+7cBJ5N/x4dDqRQdTCBRPuSmzSDy/HNIAAAQMUYDAIAAFSMwSAAAEDFbmxmMMpzaY7iUCJrT37vf4V7f9eus/7qultGC5TqD6FHNC+nBY6jLEa3m8+kuB+nX2i+x+cq9FxpviSogZzWF7YQ9fapL9B8NnnTtJ+e23U0e5ZS/ryU5AGj7IhuV48xKjCt/SspsKo5zqjQrGZmXr/3Q9u+875bZ+ub9p5aNvY8aAb1j/215+VsduqWmU53Tft4cmLaR0dHbp2SjCC+WiVZ2miZycLen8fn/9m0dx/91q0z3JPtdvNFxl0x9h2fR9t669Cu85nk3hZ33TrTrs0Rlhyzvh+igt3n5+emrc9B9B7SYzw+tgW9o/ed7jt6d5XkFXP0mQ3zzkn+bnXz+9W/SSnlM+r6vugug0LbPfujDN01/47RfHxJvhxfjm8GAQAAKsZgEAAAoGIMBgEAACrGYBAAAKBiNzb5HRXZ1IDp/bNfmfbt8f/j1pmfPb50GynlJydEAWANDmvYtdPx43RdJgo++2KjGhz229VJD9rfaD/zDftZ/7Zfpv/08v6WBLf1fEfnv2S7eo00EB4VV9Z9aeg6Kvqt60STfDT4fHvjPdPeeNs/lk1HwtByS+lkkagvkz/47Z71bNFhnQwVTjqQIHzJJB+8WCXvmOi5mA7sczGd2+dvPvPrLJb2PuoUFFcumQPRl0klW107oaT3md/PiRSmni4PTLvkfR39QIG+H3Rix+mpn4yl10Cfk5MTOzkrWia6RrpvfSZLCmu7SYFREeo/fZ5KUdFs9x7d99d1e/QL07539pdumfO1n5i2XtfoRw3w5fhmEAAAoGIMBgEAACrGYBAAAKBiNzYzGGVFNHuhuYqH579w67z//n+x68w/csvc+4HNJmxs28LUUW5sudTchxZO9lmtwcBerqhwqB6jXyb6UfPLi1lHBZk1j7Ho+mKp89l909ZsTpTTizIzZj/BddXPwoyjfLa1tWXaUaFwzQ3peYjOixZUvX37tltGM4OTc9v/2cRf+75kPzU3NJv5fMyTf7MFhT8/+Au3zOnQFrgejWzh9SgDpPuOiuni66fvgihDpffr8eD3pn3w+LtuneEnH5r26C3735vG/1nx78B8QK1vH9E0euPALdO5L++uua2QP+vZ3GFK/p0Yv5/tudNnPcoL698TXSc6//rsRPlFXU/7VlKoOtdOyect5+fB3yDpXmfNLfLc+iN//vtrUti+63/soSSbj3J8MwgAAFAxBoMAAAAVYzAIAABQsRubGYxopkCzGA9PP3frHI3/X9P+5MmfuWX+w9jmPu78yOauNOuXks+pRBlBpfme1cpnRfx+8j8c7tnztFj4/WhOb7n0Wb7p1P5QezqzuY8oQ6M5EM2nRZkazcxEuULdjuaG9NymlNL29valfSup8xgtc2/+LdMevWKzlaugL5OJzR/p8Yw/9PsZn/+9XWf0O7fM8uLybFSUB9Rl+EH4l1NJZlCfg8OBrau6NvVZ2t7H9h34SsfmDDfe9H3R56KkNp7qb/n86uiNp3Y/D+TenP2NW2eja/N+/dWmW2a4tMc9lFPX6frzoq/wtZVdab4Izv9U3l0X77tlThe2pqG+36LnTz8ryRmeNZ+a9tb4NbfM2ol9V/Vu2WtW0pcSXamH2+34v2NkBq8W3wwCAABUjMEgAABAxRgMAgAAVIzBIAAAQMWqmkCiNER7cOCLmqrJwhcavvvBj037dPzAtEf7vkDp4K4Nv/aHNiAbFUHWQqdRMFdDtLmJEyn5cLeuE02CcBMYPvXh6Eefv23axws7QWe8sEWRo+3qNYr6UvID5bmwsRaYTslPKllftxNgtHh0Sv5cvr3+n9wyr7xuQ+KDO3Y78WQce99NH9plDj+zxXZTSunJ/AO7ztpJsF07Iefw0BbpjSbj6PkluP1y0usSPTv6PtDrfTh/5NbZmrxt2tvH9n7ov+Lvh2iC1lXoy9yP9ddtIfvu8l/dOsN1+7z1u8H7Wd61vYF9rjvB9yi9lRR2TvJ+XvjzvyWFnaf3fWH4zsJeg/nSbif6O5CbVBetM17Z9/G8+7ZbZiETztIyX8xa96XLdDr+XOpHvW5+EqbeY9G7C1+ObwYBAAAqxmAQAACgYgwGAQAAKlZ1ZlCVZAyePn3qPvsfk5+a9q3DV0z73rotMpxSShsDW5B5d88W89z7lv9h7sGGvVz9jr98vQ3JtkgcJsruaJ5OM2FRoefpgc2tnHzoMyhPJja/M5YfjY/yi5ov0aLH0TXSZaJslB63Fk7WdrQvzahohjCllPZX3zXt3dHPfF/ubtn9rOSYVj53szi1WZ3zB/Y8na1uuXXmazabGGUpz87sNWpT0BbXQ5Tn0uutz0H0vjjs/ta0d57YZdZu+edvXSKtcdHp/DJ+HbvMYMO2u/3gmHuSS+7452Ipx93rPf/3Ji4rt+b7ciFFpy9m526ZyVKyfCst+O8LSOt5KXmunc6p+6jp2PVWmpO8qvzwSgqMd/wx6vv4RdG/UyVZ/euIbwYBAAAqxmAQAACgYgwGAQAAKkZm8DlF2YAn4yemfTK39dxOt33OcDiwebPe43373z8auXXWN22O4u7om26Zve1/N+3BwF7i5fINt06/Z+tYbdyz+YzVms9IHH9os0UPDv7SLTNes9mijmQvGv1l9+QzbKenNrei9b+iz6IMjeYItUbgxsaGW0ezkpqfiuoMDpO9rkEJs7TsSxZRutsE0dXzz6T+29mPTPt08Gu3zoXUKzw/D/JIkrfUY4zyl9TvujlymcHoeTvp2+zvg/PvmHbnfVtPNKWUbkt77VZJZvD5v6vI1VlNyWfANDOdUkoLqQkYLZPvi22vVsF76dQuNJn5/Zyv7HtIj7EkM6jLlGTclkFObynHIBHC8Dzlrkl0XlwW8dKeXp0oB66fleTWo2vysuObQQAAgIoxGAQAAKgYg0EAAICKMRgEAACoGBNIXgAt7vvkxE8g0RBzNz007Y11P6FhrTM07ePZx26Z7ZmdiDIa2UkOnZ7/4fl+I5NVjjUw64tOjyXofDD+F7fMSuo464SLqOi0hnVLik7v7u6a9nA4dMtoMF4nh0RFp3UyxdaWLRZ9Z/OuW+e1gT2mW9/Ycct0+lJAemwndkwe+GN89KktZv3J7B/tAms+uK3h/6jodHTcz7qOQWiU03C/3iP6/KXkn9vH6femvTr1RfbT+/b9tv9tP7FDC1P7P0/5iUuu0HMwUUKX+aqKF18c+GM+/cOeaT9dfOrXa+w10WMqOcY2heLnjX+PLi/sdnoyySfqy3J5eZHs2SP/jjk5ftu2F793y7QqpC302oeTAoO/J7ntXMf3Jt8MAgAAVIzBIAAAQMUYDAIAAFSMzOBzivIlms3SwptRzk0za7rO9CLIctla1mHmbm/PFm3ea/ZMO8o/NM3RpX2J8g+nE1sM+ujsyC2jdN9RQVvN6W1ubtr9nvofT9fcW1QoWYtZazYqukb37t0z7Z0dm/97Y/3Hbp07935u2v1X/DEuV/YeGkjV6U8/8rmbj8/eMe3j+bFpD5f+umreS89BSv64o3OHeuizHj0X+uzo++Kg85Fbpzf+tv3gg6Awtb5bb+kS0Z8rKeDezWfY9Jh6Pb/dbvfyItMlRZt1kYsDv8zJ7BumfdD8LLuvNtm4kv7eSjaXvLHhC9l3t/W82HZJflHvn9nEZ5knU5vdezrxWXd977fJ6eX6lpK/p6Jnos01ednwzSAAAEDFGAwCAABUjMEgAABAxRgMAgAAVIwJJM8pCopq6H40GrlllIZQSwqJqmgyy/m5LWCs29HCySnFhTafdXJykv0smnigk0FKgrhHR0emvbFhi29rUeqUyiaQaLi4JPCrwfjX139o2m+8+ju3zuhtO+FluvIFuxsp3Dr90J6ni+Ebbp1ZzwbLm4vLiwWn5CcYbW9vu2VyRYZvQjAa7ZVMINHnOprY9rT7kWl3zn1h6t4HtjD1ni5wK5qcYPfd7fbkv/v7t9PpZpfJHVPJRAk19fO30nRhJ8QtGn++S/4WKH13Fa3TyA8hBKMD+d2Doveqvo/dBJLgHTmbHdr9TP15uYoJJLltRtuNC2tfvyLTim8GAQAAKsZgEAAAoGIMBgEAACpGZvAKaE4iKu57FTTHokWQU/IZu5IfntcMhGYetfBzSj5DMx6Ps9vNZQijZTSLEeUBSwpIa9bw9u3bl+43pZT29/dN+63bNnN36xv+vKQdu+/pb32+5MnH3zftz88+Mu0H49+4dfS66bktKRYdnW9dj4wgnhVlofR502cnev703nuSPvQ7O7M5wuX79017922fRVy7JTm37uUZwpRS6vXsMsulfy60ELU+F1EmT5eZfGCf0cNjX6T+pLHP+nz1/M9xST5Qlxk2Pie+1bfZvcGu324uvrhc+vfHxYU9Jn3nnN33eefjc7uj8cT/fdHtlBQcz+Uvo/9eSyF+vhkEAACoGINBAACAijEYBAAAqBiZwWtEMymHh4duGa0zqHmeqAaYZi00MxjVp9PPotyK1iLUrFGUR9L+53IhKaU0HA7dZ0pzTLrvqH6hq7/Ysce88tGotHhoMydnB990y5wkW09t3Htsd9P310j7p+clqo81nU6zy5ARxGVKaqrps1WSsYruu0er39vtLt827em7fp21tQem3esNTHt9y7+XRq/Yd+JgJ3on2mPsLu0yHbubP/bvE9s+OPxb0z5qfunWmST7vivJ/+k1id7patjYd+Td7ttumZ27tm5qfz/fl9XKnqfl0r8U9f44fsf+HXj4+K/dOk/n/2ras4XPFeq5GgzsRYnOi953eq/ehHqBbfHNIAAAQMUYDAIAAFSMwSAAAEDFGAwCAABUjAkkX4GooLFOhNCQbUmwPwp366QBV2w0mGyxtbVl2jqBZHd3162jwdvT01O3jPZP+1ZSQFpFAetoUkluuzq5JQob6zrHWrD7I3/+F4s903409oHkh6cfmfZ0bid2RPeLfqbnMrpfmByCF0Hvq5J7Ud8FJRNTHvXeN+3Z/J5bpz99xbS7PSmgP7b/PaWUNp7ayVjDvv+RgK68D1bJvgN7XT9R4qKxExhOZMKIThZJyb/PondZyTJqo2OP8W7/G6a9+8q7bp3BK1LMOhgd6HXTaxZNwDh7z56rR0/+xrQfz/+HW+d0bv+eRPeUngedZKcTSlLyf3OiAum14ptBAACAijEYBAAAqBiDQQAAgIqRGbzhcj/MnVK+eGeUUSkp1qn71qLHbTJt0fFo7mNjY8Mto7lILSgdFZ3W8/L55Gem/XDsMyndrs0Fnc2O3TJPjw5MuyS3cnZmc02aZyw5l1HesuT+wMuvJJccPaNtiuzmCiNH29RcYbSMvnf03jzofJ7tm2Z/1/v33TJrS5ubHsxHbpm+ZgZ7H9j9BIG6Jsn7Ltn3XfQe1c+i51GPSZ/19eRz4Hf7ttj97r3fmvbgnr+GekjRq0H3re3T3/l32aPHNiP4cPYvpn1wbt+HKcUF8pXm3/WdXlJ0uiR/WQvOBAAAQMUYDAIAAFSMwSAAAEDFyAx+BV6mWkZRXzR/dnR0ZNpRDUHNdETb1RyTtqN1NOehmY6odpSuE9VS3NzcvHQ7UUZFc3qTnq0zGOW0tC9Pnz51y+j5/ap+HJ184PUQ5Zg061Ryz+v9WZIZ1Huk5N2lWa2IbjfKuOq+NJsYZcCUHs80+bql88Yu0+1O3TK9Rt5DK3tN2tQDjI45l7+M1tvo2kz0nWTzgSmltHPX1hHs3ZVsYtB/fy/4viyX9hqdvGuz458/+Cu3zoPpT0z7WHLUUb1ZvV+ie0zv+eh9rHKZx5rxzSAAAEDFGAwCAABUjMEgAABAxRgMAgAAVIwJJJWJQuSHh4emfXJyYtpRiFwDvlF4VydplATNtfiztqPAtQbLo6C5fqZ9iQpVHx/boLOel2gyi57fyWTilskF+6NANW62Xq/3P+/tkskJeg9F96JuJ9ruRt+G8FdSOPli6e9FDd3rvksmepRMnNDttFknou+uaGJVm4kFuQkjJX2LaFHpV7pvm/b+q79z6/Tv2XbTtX2JJofoZ9HfCp0w8uDRX9v29KduHS0qrQXISyYpRecud39H17Dk2teKbwYBAAAqxmAQAACgYgwGAQAAKkZmsDJRRkIzatqOsjolWQvNguR+cD0ln8vTthaPTiml3d3dbN80/6eFtHUbUf/G47Fpa/YlpXw2MSWfxfmqik7jeoiyfbkC7lFm9173B6a93T8KtvuZaTfySC6Wr7t1Thd3THucPrQLdP3zN0u2qHv0TinJBKroXL0ILypbdqv5nmnv9n2B//X1h6Y9um0zgv17wbns28+0/8tllIm0y2g+MKWUPn9oi0prRvBwYvOBKaV0fn5u2iWZwZK8aJtMqS7T5p67qfhmEAAAoGIMBgEAACrGYBAAAKBiDAYBAAAqxgQSZJWEp0uKTmtQOAp/a5HpkoKk2r+oaPNsZgPsFxcXpq2TQ6Lt6jZKJn7oOin5iSltCtziZun3+/8zzB49SxqW12dn1Nly6+wP3zPtrTf9s9Rdt9vRCSTN4olbZ/vIfraUW/z0zE5cSSmlw/SBac96fvLVVYT5SyaU6DIlk1muom+30/fcZ3dG75j21pu+uHJ/Q669rUGdVh3//ljJpe52bf+jd87Z7+z77OFjfx0/n/zMtA/On5q2ThZJqV2R6TYTdtpMauTd+7/wzSAAAEDFGAwCAABUjMEgAABAxcgMIms4HLrPNENTktfQrE6UHdEsnxZtjrI7msuLMlf6meYKo6xLLuMY5ZM0R1iSjwEWi8Vz5dLc89f1+dVOR4rHbwTbsRHd1C3Iyq3t2vt+tbC5q7XH/+7W2Tq2z/F84fNo58k++wfpfbufFvmuknNakjNskxm8k75v26N33TKjb0p+cdO/Rzt9+5lfIvhE3seLhRSU/q3PVT9+8kPTfjj7mVtGM4JnZ2emHRXif1HvQD1GvT+i/ZIZ/HJ8MwgAAFAxBoMAAAAVYzAIAABQMTKDcHkYzdBE9fRKauXperrdaJ3JZHLpMlq7MCWfMyzJ9+g6JbkW8iV4UUpqVj5Ln6V5x9ezvFj8pV3m8Ttumd6evae7G/bZ6Q2C7wu6dp2e1Crsve6fv+Ete3yrmc8V7hzb7dy9sO3D8x+5dSbNQ7ufdNvup+OzwE2yeblV8jVGB51N0+4ke0z9NHLrrMu+9zd/Ydob3/A1BNO6vlP8+fZ5bNteLqP3kl3m7D2pIfjIZzYfX/zctA+nh24ZzVa3qSF4VfS86DOk7/iUyHBfhm8GAQAAKsZgEAAAoGIMBgEAACrGYBAAAKBiTCC5Avoj8jqBIQqHt/kh7hclF8RtKzfhIvrv2hcNKEdFTYGbpCTkrkXUZwtfRPjR8pFpn3z2V26Ztc/sxJPt/V+b9ubb/k/EYN1+ps9xr+8nSvR37Wfh+2/ffjfRyCGtHfzCrbKcywSzdTuhZOVPS+qs7Pt5Or7tllkb2O2sbUox7uAvZ3/9Y9uXXZmMY+ek/PGzXjCpROgEkWYlxZaD9/XZ7+1nJQWlj2fHpq2T+aLPvqqC0tF+cpMNmUDyfPhmEAAAoGIMBgEAACrGYBAAAKBiZAavwFVl7G6aksLUAPI066TZ2SgfNU7vm3Yv/d4tM5TiyndmthjxK+lXbp3tb9vvEPrDfO4tSdHmsDD8wObEOlJffjAMVunYvkgt7tRNwX4a+9lw7Isrd9ekEP+G/e+dnt+uxv96Pe1b9N1LvkD+/Kl9b55+av/eTCb7bp2T6aum/eTCZgSPZv6YNYMX5bO/qsydZgaj+1s/03Veplz+dcA3gwAAABVjMAgAAFAxBoMAAAAVIzMIANfMVWW3JsnWGVwsf2Haq/t/49ZZzW0twtH+mmmv7/vvGLr7NvcWZQY146UZ4yhz13GZwXwGT3fd2/fraP+0HdUH1M80shZlpvWQNB+YUkoHH94y7cdTG6aczH3+bzz9qWkfTu0yUR5wPrdFGV+mLDx58xePbwYBAAAqxmAQAACgYgwGAQAAKsZgEAAAoGJMIAEApJRSOlucmvZKJpSklNL5/T8z7c3DbdPeH/kJDRsbT017dNtP2hjczUwGCYpO6zI6ySSedJKfZOLX0e3mC22vVnYCxuxjv8x8bJc5n3zXLfNo9ti0D+Yf2e3O7CSglFIaj8emrRNGvqri0bg++GYQAACgYgwGAQAAKsZgEAAAoGJkBgEAofNm7D6bLn5p2p1z+53C4fRVt87G2r5p3zp9wy0zvG+rNG+NfmPaozu+f+v7Nrs3kHZUHFqtVo37rGlWl7bnZz5z11zY9oWNSabDgx+6dU4XdqHz5YdumUPJDF5c2B1NJhO3juYIX6YC0ng58c0gAABAxRgMAgAAVIzBIAAAQMUYDAIAAFSMCSQAgGKrJBMuZHLCwfIzt05ncd+0x8sHbpmN5bpp762+Y9qjCzsJJaWU9o/s5Iqtx0em3V/z33c0SSaDzFbBMo207TKzc9vXlFKaLv7CtC9kRsm4edetcySzTLQ4dEp+gohOIIkKSDeNnxQDXIZvBgEAACrGYBAAAKBirf+ZmK+hAbxoN/09c9OP7wt6nNFxr6SW33K1kPbcrbNY2mXm8k/WTfATvO6fiYMafP6fiW17EayzkP4tGtteNn6d1Wp1aTul/Lmr5R5CeyX3SOvB4OnpaX4hAPgTnJ6ept3d3a+7Gy9Mre/R49lR8JltP0wPv5rOXJlff90dAEIl79FO0/L/VqxWq3T//v20vb2dOp1Oqw4CQKRpmnR6eppef/311O3e3DQL71EAL8rzvEdbDwYBAABw/d3c/8sNAACALAaDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFAxBoMAAAAVYzAIAABQMQaDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFAxBoMAAAAVYzAIAABQMQaDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFAxBoMAAAAVYzAIAABQMQaDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFAxBoMAAAAVYzAIAABQMQaDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFAxBoMAAAAVYzAIAABQMQaDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFAxBoMAAAAVYzAIAABQMQaDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFAxBoMAAAAVYzAIAABQMQaDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFAxBoMAAAAVYzAIAABQMQaDAAAAFWMwCAAAUDEGgwAAABXrt11xtVql+/fvp+3t7dTpdK6yTwAq1zRNOj09Ta+//nrqdm/u/2flPQrgRXme92jrweD9+/fTW2+91XZ1AMj65JNP0ptvvvl1d+OF4T0K4EUreY+2Hgxub2+3XfVroyPjXq/nllksFqbdNM2V7Hs4HJq2fgswn8/dOtrfqC/62Wq1yq6jx722tuaWGQwGl/Y3+hZDP5vNZqYdHeNoNDJtPU8RvUYRPcboPCyXS9PW/uu5jPYdHZNup+S+U3ruUvLHoO3ovOT+32B0Xvp9+1qIzoOeuzYu+ybsi35dx/fM87jpxwfg61fynmk9GLyO/6TRZkCjfyzbHndu3yV9abOf6I99m31/VeuU/JNgm2Wi86CDnJJ1XtR5yG2jxIu6h17Us57bbtM01/I98zxu+vEB+PqVvGdubhgHAAAAWa2/GbyO9J+2Sv7ZVUUj7JJvqkr+CVJdXFxk963/pLexsZFdJ7eNlPw/Hef+OTral25D/+k52nfJ+S3pi17r6BrpvnWd6J9dS2IDuq+Sb2vbfANd8s/P+s/YJf+8W3LudF8l8YSSb4G/uEeapknT6TTbVwDAn45vBgEAACrGYBAAAKBiDAYBAAAqxmAQAACgYtd2AokG2KMwelQD7lklkzg09B5NtiiZQKKBeq0jF00Y0GOMltG6fDppI1pHjzuaeJCrhVcykUL7phNiou2UTPTITV5IqawWocpN/EjJ31PRfnJ1HKOJEfpZyQSSkmvQpk6mTiCJzm+b7eo60WSWL5a5qvqeAIA8vhkEAACoGINBAACAijEYBAAAqNi1zQy2Kf6b+23XEm1+/zVaTzNhUUHmNv3N/cRaSj7TFu07l5+LMoW5gsZR3rKk2LJ+dhW/i/tl/cn995JcoRqPx6YdZVl1XyVFm0sypXrfaW4zuo56P0TnW4+hJH9b4ovtkBkEgK8O3wwCAABUjMEgAABAxRgMAgAAVOzaZgY1oxTlpXLZpygLlasrWJLlKsluaVYryqfpOtG+NQOmx6S1/iIlx6T9K8nKaV9K8mklWTHdTnQdS65bTpQP1fuu5LrpMUbrlNQv1Gup50FrV6bk7482tQlLaj/qeSnJ1kb3w7OZwavKIQIALsc3gwAAABVjMAgAAFAxBoMAAAAVYzAIAABQsWs7gURFwXgNsZcUK9aJESXB+BK5CRca9E+pbDLI2tqaaWtIPwr/lxRO1nC/tqPt5ib1RPspKdid209E74ermoxQckw6uUKvY3SvlhQY189K7u/cfRedl5J7KLpfc+vovpggAgAvB74ZBAAAqBiDQQAAgIoxGAQAAKjYtc0Mai6rpJBviVx2K8pCleS9nne/0b6iIr2aCdNltOBxSv68lBQVHnalcPJqw/c32fxis35u2su+P8aSHGcup1mSO4zyaVdxnUpykLms35f1L7eMnruSPGtJsfCSbJ/eHyX36vm5vR8uu+ebpml1fQAAz49vBgEAACrGYBAAAKBiDAYBAAAqxmAQAACgYtd2AklJMWgNoGuB5iigrpMr2hSqLinirKL9RJM/1Gw2M+2SSTO63WjyjR7Dfu+7pn1n+z23ztrW1LRPDv/etD9rfu7XkWtScu5Kijjr/RGdf92Onrtou9q/6LrperrdkkLVUVHn3GSm6DrmioVH94s+SyUTSEqeE+1L9Mx+sd2maVpNAAMAPD++GQQAAKgYg0EAAICKMRgEAACo2LXNDGr2KSo8rJkkbZcUKy7JA6ooY6Wf6b6j7ZZk4zSHdVWFerV/g+6maa9v+gzecN/eTvPxoWlvBoWqL5K9JtF50FxhSV60JMOWy+BFfSm5/rmsquY8o32vr6+7ZfQ4tS8lGdg290tJMWvdTnT+S85dlJUEALxYfDMIAABQMQaDAAAAFWMwCAAAULFrmxksydMpzZpF2T7NNeXqtEXrRLknXUYzYVH/NVsWLaOfaX+jYyzRS7a/o77k4NZtDi6llE4//yvT/rTzjml3B/7cDZKteVhyHUvyom3qUOo9FZ27kvtBc3p6P0THqMtE+TqtD1lyP2s9QF2mJFsZ0fV0P1Fdx1xGM6WyOpkAgKvFN4MAAAAVYzAIAABQMQaDAAAAFWMwCAAAULFrO4GkpMhtThTSHw6Hpq0Fg6PJIdPpNLsv7a8G5aMwvU4YKCmCrPs5PT116+hkio0NXwx6b/CWaa8Pf2P727d9Symlprtl2v2uvb2iYywp/J2bKBFNnCiZYKSf6SSI6J4quc908kTJddRrEt1nuQLSkVyhaj3mlK7m2Wrri2Nqmqb15CcAwPPhm0EAAICKMRgEAACoGINBAACAil3bzKCKsk/6meanokLEuSxflK/TZaKMleafdD8lBYO1UHVKPt+l24nW0WMIs3wru0y/b5fpLPz5XnTPTXvQs1m5koxbRI9R250oWiafTTsTt8hEC3ZLoe1Vz2/4YmnvmZI8nZ7f6F7VcxNtN5dxjAo25zKCmmeMttMmqxo9W/pZtO8vPmuaxhVdBwC8GHwzCAAAUDEGgwAAABVjMAgAAFCxG5MZjOrIaUZJc1hRFkozd1rvLcpC6TpRX3LrRHRf4/HYLZPLkWndxJTirJZa6+zY9tBm2prFplvnbO0Ppt1Ldp0oM1hSZ1Cv01pj+7+d/sytM0g2K3k6eOqWOe8fmvZyIdlPH8FLB4t3TXvW9QvpMWn/o3tI77PoGkX36/P892g/0X1YknFsc8+rKOP4xblpsz0AZaJ3Rckzl6vF+rI/t9G77FnRu/mrou/dtn8vn33HP8/14JtBAACAijEYBAAAqBiDQQAAgIoxGAQAAKjYjZlAEhXpzQXh24RdNYCfkg96RiHVXHHitoFePcbc5IXos0HyQdWN/olpr23b7c5O/KSNbu/95+pb9Nmwu+aW2eq+Ztr7fTt5ZeeV99w6g1u2PT/x53J6Yq/lfGXb44OpW6f/+Y9M+zR97JY5Sg9NO1dwPFomotdNizJH90sucBzdq2tr9hpExZ/1fi4pvl3St5LzAOBy+jep5G9Jm4mPL/OEkZK/qbpMyd+oaJKJvkd1uyU/KtGm2H9uouHzFO/nm0EAAICKMRgEAACoGINBAACAit2YzGBJMUb9N/moqGOuKGVEMwRRX3LbLVknymVpBmI0Gj3XflNKabP7ivtsbfChafdku2vnD9w6/d7luYkSt7t/4z5749V3THvnu8d2v4Ndt47ue3nHnzu9bpqt2DzyBbtHdz4y7ScfTNwy75/aTONZssXCo+tYksXJ5V2i872+botv5wqxR8uUFJ0uyQyWZEjJDOKmKsmjRfd/m2fiRWX7XsTzGb239LyUvF9K8nRR5v95Rf3Vd6SOLaZTnz/XYyrJlqvoemhmsBTfDAIAAFSMwSAAAEDFGAwCAABUjMEgAABAxa7tBBINmEaTQTQ8qe2SIH/JxJTcNlLKB0yjYGvJBIHcMZY4W/nJIMvVj0y723wifbGTOFJKaWN127SnPTtxIur/phSQ3h8duWVu/YWdvDLa2TBtLZKcUko9mcyyWvprMpdzPp3YkO9a/9yts7Ylk2SW/r6bvvcd0/5g+S+mvQyCzSXXUe8ZvX+jYqj6mYaSS4qoR9ct2leOPhdMFkFNSu733ISAlMomV3xVxaC1b9F+dZmSH38omTyZ06aQfzTp5Com8ETv0Nx2S85lND5pe+35ZhAAAKBiDAYBAAAqxmAQAACgYtc2M6iifydvk2vK5RtKsgvRMrlil1H/dTtRLjL3I9pRwWDdbnfll1ksbJ5hdm6326xs1i+llC46PmOX68vtte+b9u7+B26Zzd0d097e3jLt0YbNFKaUUjqz+1qc+kX0mjSHUhz6IvgR8D0pZv0tf63vHv3WtI8//5ZpP1i979bRa1Jy3TY37TWI7nctdqo5lZKsbXQ/5wpIt3n2gMuUFPstydO9TPdmmzxam2L+L0qb4tCqpKj9VcndL1H+vKQvuh392xKdl1z+ryQ3nruXKToNAACAIgwGAQAAKsZgEAAAoGLXNjNYUrNM/w1eawhF/56un+Vqu0WiHJYq2Y7mAaKsyGhk83KaiYjyGGrSTNxnjfz/hL6N7aX++sytc/f47037af/fs30ZrdkNb+1t+GVG9rPt7W3T3lxJ51JKs8k3Tfug6+sizhp7DR50PzXtnfnfunWG0/9q+7buMxu7b9rtvnpir9Fp448x96Pl0TJ6f0wm/jrqdvQazGb+OpbIZQajZ6BNngjXT/Scl+TctAZmSY3XXOarpPZmyX7W19dNO8qAv6gsYi7DG51b/Vun74GS2oRt6tpG1z7X/6i2n64TXSPtn263pH6hbrfkfVjybtN7oST/p33T5yFaJ7oPqTMIAACA58ZgEAAAoGIMBgEAACrGYBAAAKBi13YCSQkNW2o7Cmjmwq4lQdY2P0odKdlurrhlFBTWkHXUt+nchnovDu0yI1tHOaWUUn/xM9OeL1+z7b4vSt0byCSfrg8Trw9teHtzwxZb3l3ecuss7/7QtGerX7plDk/spJLtxk5MWVz4/jZPfmDane5P3TKbr9hrsvf4c9O+Pf4bt85Z959NOwop62d6r0YB9lwQuyRsHAW89V7UZ6lku5cVEW6a5qUqDowvl3vPplQ2OUEnaago3J+770omFkbv9NyEi5L3eZvi0CV/X0rOZe45jyZ66DrRMeozqdd6OBxmt5v7AYaU8hNgou3qeYjWyf1Nje7dkglHWty/5FyqNu/m6Hw/+5xQdBoAAABFGAwCAABUjMEgAABAxW50ZjCXH4n+vT2XFYnW0axLlHXSbIvm9qJ/22/zY9clP2RdkpPorGwB4/62/HcfI0vrd+x27zx91bQP+7aoc0opHfV+bdqT8T+4ZXqzh6Y9OLWZwVX3/3TrTG59bNr76bbvcM/+fyEt2vzw9IHvb//ItNeOf+yWGY7/u2lvv2nvjztP33PrPJnbQtSnQcZE75mSIqslucLcOtE9nyuIHmVkSgrffrFM28KpePH0Wmv+7LLreplc9rAki63vzMtyqV8oKU5c8iMHKpdpS8kfY5Sb1PVKfowgVwQ5ygzqcx5tN5cZ1HdUSvmMZpQFLemLbkf/xkbZxFzR/ei86DWJ/l7qvnIFpVPy51K3UZLZjPKLFJ0GAADAc2MwCAAAUDEGgwAAABW7MZnBkppOukyUz8hlRUpozaGUfDahTX9LMiclcrUUU0rpbGlr7J1+bLMKo7v+vIzu2vZw9Tv7weRv3Trj7h9Me9rxeYfJZ1J/6S0bWOze9jmV0Whk2tF11FyK1rYqqcV12P+NW+bWxOYIhzv/n2nvvervj9fGdp1Z+me3TC4LEuVHNGOi7ajWpm5Hs5Qp5XOn0fkuqdn5xTGSGXx56bWP3h85JZnSNjk9Fb0f9b4rydGWvGfb1MXUjN3W1pZbRs+v/i2JnpVczbowJ17wN0n/Zuo7suRvlF7HaB09L9G7WI9J399RfjHXl+hclmRXS+oiqpLMtyrJXbfFN4MAAAAVYzAIAABQMQaDAAAAFWMwCAAAULEbPYFEw64lxSM1dFpSHPrk5MS0oyKaGvR8UaHrkh+NV9EyjxbvmvbW0X827Z1P33frbH7P9mVt356rncV9t86ya8/vQccXZP7dZM+0T05sUPvNnZ+5dW5d3DLtsGipXIK1pUwoWfrK2iWB41my++oeSGHZO/6x2/z0F7YvM7/vi44tSqqh5agvuWLQJYVNS4Lluk7J/X3ZD8kzgeTlpddGJytEwX29H6KJS20C9TklQf6S92pJAWmd5FAyoWFz0xbQ39jYcMvohMTzczu5LyqunDvuaPKW/h0omZhSMrlCl9GJe9Exl0zyyU1I0/Ofkj8m7W80WU7v1Wi70QSXy/qaUtkPRKgX+V7km0EAAICKMRgEAACoGINBAACAit2YzGBJ9klFuQnNA+gyJf/2X1LQs00R0JL8i2YXSop1RvvW4zyc/960jz73mZ/tb9rsytquzcis7x65dW5N/g+73/Sp7+/CHrdmZo6O/HZ7ktvrN8EPqJ98w7T3F++Y9nT5mlvn88Vnph1dk7XG3jPDW7YvFwf+fC+avzftWfOPfhm5n0vuh9wPpkfZrdy9elUuu+ebprnSgqq4OrncVZQb089KMmvRvZmj24h+WKAk35orzB+9VzX/l8sQRv1tU6y9pNi87idaR/sbLaNKtqufleyn5J7S9Ury3G0y9iXv2ejaPqvkPavn5apyhqX4ZhAAAKBiDAYBAAAqxmAQAACgYgwGAQAAKnZjJpBEtBinFpSMwqIayMwFiaPPSgKnKgq7aqA0KlqaC82WhP9L+nu8emTah+f/2S2z+54tRD34K1t8e7Dn+7+/96+m3Z9su2Wm8x+a9vzsqWmfdk/dOutnb9r9DH/nlund+Y1pd/fsdnpHn7h1Ni/+3LQPlz9xy5yvxqbdfypFeV/1/x9s57Nfmvb2+a5b5qJn7+eSMLEWrNVnInoG9J5pU9S2RLTvL0LhTCB5OUTh/tFoZNp6L0SFe0veS7kwf5sC0tE9VDIBQ5W8R3OTKaL9aH9LnjXdjhZxTslPaCiZWFhSPLykyHROm8kh0QQNXa9kgl3umkTHrD8iEf2oxNbWlmnrhJFonVzfIiXn/9nz8DyT//hmEAAAoGIMBgEAACrGYBAAAKBiNyYzWJJdKPl3e11GswrRv8FrPiDKQmnxU82GRNmWkv6qkh9HLykqnMtOftb9F7fO1qP/aPuyaQtVd1/xt9vwG7Z/axt+me3xr+wHkx/YdRqb10gppf7WfzPt6T2fH9Hrdn5qi1nPuradUkq9+aFpRxmfZm6PqTOSTOlZkB1qbBaxGfzGLZMrShrlgKKiu8+K8l25jFK075J7qmSZL/b9In+QHeVKikOXvMuid6LKFVcuofdNlKPV7UZ/O3J53Khv+r7WbUT3tH4WPcNaZF/XiZ5xzRHqdkuywiWFqVWU0yvJCF6FkuuaU7JOdE/pvavt6HznzmX0t0X3HfW37buTbwYBAAAqxmAQAACgYgwGAQAAKnZtM4OaD7jsR++/TJTJ07psJTmEkh+L1iyf5jyibWj/SuoxqZIMR8mPaKuLle/vR+c/N+2T9//MtL99bOsDppTScF/qR/kyg2n0qs1frK//1LR7A5+LPO3Z89L4Xaf53GYyphN7vo/v+/vj6bnNY8zmfpnz1RPT3pTo4fpr/l7dGP3BrnP8mlvmJL1n2ppLie5nvbYlecCS+miaZ7mKuoMp/a/nuGma8L7EV+uyXOeXLVOSwYtyhbrdkntV91Vy75ZkqnLLlORoVcm7uE1fouxZ7ryU1Bks+Zvapn6kis5L7h6L+qLHFK3TpiZwSV1HpX2Jcp3al1xOP6X8Madk+/s871G+GQQAAKgYg0EAAICKMRgEAACoGINBAACAil3bCSS5sHFK+RBtSXhXQ54lhUOj7ebCxdF/1+1EP9atx5QLpZb0Jdp3rtBsSilNpX9PFu+b9ubhf3LrrL/zW9Oe/7kPu06ndmLE+roN8A6CCSQ9nUCyCgprX9jzMH1gz9XTB2+5dQ4vPrD9Xfn+Pkn2uNfGf2fa3Yc/cesM921794EvpH1f7rM2RXpLCgS3CdhrOyp2rqJg8xfboej0yyF6r+YmD5W8V6NJBbl3erTd3ISG6P1XMukhN3klCu7rBC6daBA9ayVFhHU7+ncg6ot+pu2SiWMl17FkosdVTAS7iok2KZWNG1TJxJrcxJSSyU9tCqZHnt3387xH+WYQAACgYgwGAQAAKsZgEAAAoGLXNjOYy7SllC9AGuXe2hTPzWUTIyVZi5IMRy7TqEW0IyUZCM0vtPkx+ifdX7rP1j/9rt1u875bZrhlj2G4JwW8d30+rduxfVkd+/6c37ftx+d/Yfvb/MatU5I32kgbpt3p2Z13hkGO49g+iouezwzm7vkoY5LLnUb3VJuC0rqdkqwWXn7RNYuKmz+r5D2Ve1eU9kW3m8thtd2XtqO/Hbl9leRzo1y45m+1HZ1vzQjqdkve+SVymfXoszbXqOR+KfmbmttuSTH0Enp/tPlRjJLi7VHfSn4EI8I3gwAAABVjMAgAAFAxBoMAAAAVu7aZwZKaPKrkR8xzeYxonTYZK/23/5IfpY7yDNqfKHOSE9WpUpoTijIQWk9K+3aYDtw6Z8ufmvbeB3fcMtsDW+/v1vqnpn37ez4XuXpij+n45B/cMg86P5dPfuGWaeM0nZr2zsr+SPnoyN+rs4n9bLY4ccvoPaL3Q5Tlmkwml26j5BmInq2S+miqJB/1RX+apmmVYcLXL3qX6f1S8o7U+nolOT29n6P9lNSFzWXUou3m3qPRedFnbXNz0y2Tq3PXJo9Wkmsv+Zuq7/ySzF2b2n6RXPYw2k9uu9E1Kjnf+p7V6xrtV/P8ei5L6l9Gyzx7Hz7Pe5RvBgEAACrGYBAAAKBiDAYBAAAqxmAQAACgYtd2AkkJDXpq4LTkR9g1oBmFhNsU0dRwbhQw1f5HEwQ0HFoSFl1ftxMaSibFaJg7CijnArBRIFn7crB65JY5a45Mezr/tmkf/nTfrTMdfGz7Nvgnt0zu/ojoPVOyzqxrz8vFzAfhlyt7bhbNxC1zFfQaXTaJ43m0Kcx62Q/YU6D65ZUrfFty7Urul1xB/UjJjxGokndvyb5z79WoLyUT/nLvHJ2sULKN6PyX/O3QZzY3aTCl/Duy7d9U3VfJpLbcvRuto3/7Sor7t3mHltxzl70zo30/z3uUbwYBAAAqxmAQAACgYgwGAQAAKnajM4P67/iaTYj+/V1zE7pOSb6upC8qynC0KdaZ63/Ul+g86L50mSinouu0yaCU/Bj9Re9d0w6zOI38MPvSL5MrQh5ds9wP2KeUUi9JNrV/ZhfY8OelM7fnbiPdc8uk9FvT0vMS3R96bvR+KMm/RPdQSZ41t06EQtMvl+gZKCns3EbJ/ZFTUth8Y2PDtNsUVc8V+02p7H2o/Sv5AYA2WWcV9aUkX6bXXvtb0hddJ7pGev5LfpSh5P2t+9K/PyXnvyS3p/tu86MYJc9e1N+SfYX7b7UWAAAAbgQGgwAAABVjMAgAAFAxBoMAAAAVu9ETSHIB+5Lgc0mYXvdTUuyyZGLKeDzO9i9X3DLqr35WUrT0/PzctKMJAxrO1dBv1Fc9d22KdbYtUKzXvyTAWxIk30qvmvZa/9/sOtu+L+OPbSj56ew9t0wuGFxSSLZkAozeH9EyuUlT0bkrCZszgeTlEl37knvoKvbVpsi0tqP7SZ+jkslPWng4uv9zRfZLCjKXvK/baDN5q+Tal0wY0X2XTIIokTt3bfoW0fdq1F89ppJ7ObdMyd+fqP/PftY0jfvb/WX4ZhAAAKBiDAYBAAAqxmAQAACgYjc6M3gV2RZdp6RAc5Td0vxISWHIkgKquTxGlJmZTqemHWUG9bPNzU3Tjo6xTd5PleQ82vyAfRtRHiOXDUkppU7asct0PjPt6WN/jOent037ePmJWyZ3nJprSsn3V3Oo0TXT/UT5KF1P783o3OmzE91DX1z/F3VN8afLvbuia1+SBW1TvDpXeDh6X2uGqqQYtB6TFq6O+qL3sL5DUyrLjl9FZlCVvKuj89LmHa/nLvc3K6WU1tfXs9vN/a0oeYeU/F0umROg965up+THH7S/0fOg93OUd332fD7Pe5RvBgEAACrGYBAAAKBiDAYBAAAqdqMzg220+YFpFWVmcvWvSnIIJXXkNOtXUquoJJNSUl8vl7+IsiFbW1umnatfF8nVWor68mX9yW1X14muybj7yLTPz+wxdTb8fmfzW3Y/zaeX9q20L5op0fMQHWOb+m4lWdXn/bF2coPXU5v6rSn5nJ7eLyXb1WVK6shFmWntiy4TraP3q+47Wkefm+idVFL/NNeXEiXr5M5nlGvPHWO0za2BzVeuNXtumdPOI/fZs0qOp6TGpJ7vkjkB+v6LzovS7Wq2P3IVOf3/ua0r2xIAAACuHQaDAAAAFWMwCAAAUDEGgwAAABWregJJFMTNhfJLQqmXFdP9su1cVVi+JHRdEjrVsHPJJBPdV+5H5FMqOw+5UHi03ZLJK7od3U80CULXifp72LMFo0fTf7D7efiOW+d0arczvvA/Lq5hZw0YR5NvtEhpybkrKRCsy+i5i8738wTfmTxyfZS8T0omrelneg+UFEjXZaJJG7m+RetpO5oQoM9ASUHpkndkbrJWWPg+8/em5BmP5ApGlxTj1vNyr/89t84rWx/a/fTO3DJn5//p0v0cLv7g11k9Nu1hstf1rGuL8qfk36slxbh1mZJrr/uJruvzTvZsmqZokkxKfDMIAABQNQaDAAAAFWMwCAAAULGqM4PRv8m3zVLktvtVZaA0U1CS04uKAWvWTH84PFpHMzP6w+wlOZso45grdBr1pc35LimKXJJB0mP4fPU/TLu/8OdhvPzJpdtIKZ/Niu7dXF4nyqCU/Bh6bj+R3A/Wp9Su6Di+WnqtS/LFJc9WLu9ckvstycbpOiX5xZJi/rk8XckzHb0jc5nBkmLcJUryxMPh0LRz5ymllHZ7d0z7ztp3TXtv+1dunZ0/t9nDbvCu2Hv6W9Nu5FLvH/prfzGz/T3p2rziuOP/bpwsbc7ws94v3TK5otLRfZjLXeu5jpbJ/R1+nr+DfDMIAABQMQaDAAAAFWMwCAAAULGqM4ORXOYuymdcRc7wquR+LD2lsnyXZhE0R1aSmSn5kfg2PyzfJjNTUqOsZJ02+ZyJyz7N3TJ6D0XnN1fzMjp3mmXR+7sk+1miJPuUq0P5bP+apinKmeGrp/dZSW1TFV17fceUrJPbd3QPaRZrd3fXLZN7L7XJhZdkHqNlcrXlSuo8qpL8YrRffa71XG4Nttw694Z/Zdqv3vt3095+06+ztis1GnvBu/iW1IVd2PZo7PPH06m9h9Yfv2vakxO/zuZTW8910PxHt8zvl//d9q3FM6DnO3qHTiaT7Hbb5q75ZhAAAKBiDAYBAAAqxmAQAACgYgwGAQAAKsYEEvFVhdY1PFoy0aMk7F/yA9klQVXdl243WicqkvmsqHixbnc0GmX7okHtNhNiUsr/uHikJBicC4VH+9HwfNRfXa9kHb1OJetof6PzmyuEG8kVWX12O19VkXZcLrr2eq1LAuslE8Ny1zx6bnLvgmi/Je8PLZ6cm7yVkn+WtB29H0sKPev7uqRQf25CWnRe9LOogLR+pj9GcHv4tlvntZ33TPvuX9gJO8Nd/7ckN2kmpWiSo213e8EPLgzkXK3J5L7b/lx2dmVi5ANfJLt//zXTfnd83+63YMKRntuSe+wq8c0gAABAxRgMAgAAVIzBIAAAQMXIDH5NNHcT5TNKslua1ynJvekyUX5EsyC6TFQgNsoE5vajxzSdTt0ymnvT8xJlK/QYo2Xa5N5K8ka57FB0ja4iCxJlt3J5rrbZvFwx9pIcWXTuvjg3ZAZfDtF1yOVmS/Jobe73qC+aLSu5b3SZXLHrlPz9HB1j9A5/3r6VvCNLMtK6r5IC9dr/jY0Nt4x+tjvcMe1XRn/m1rn3Dft3YfdVu43ovOkxRu9MvSb+uubPk9tv8Cegu2nba2/4ZXbmR6Z9a/amaT9afOS3mynyHd0vuk70HD27naZpin8Ug28GAQAAKsZgEAAAoGIMBgEAACrGYBAAAKBiTCB5AaKAr4ZBNdQZBe51EkcUtM2FodtOTNACqXpMUX9zxaH1eCLRJI6SMHFunYieq5IAr4bnoyC2bkfPSzTRRvtSEiTXiTVbW1tundzklZKJNSXFzkuKcavoWn9x3E3TFAX78WKVFEEuKapect/pPZ8rthwpmQSm+4neZbni/W0mepQU3o7kJq1d9hx92Taios76fo4mkOiPAri/UVv+XdFb/NCuc/LQ7ufNYBjSs9e65AcLUnr+iTXLxeU/2vDHz+Rd1wR/fwby4wnpddPu9T7xq8j7ezKZmHZ0zCV/z0v+9kX4ZhAAAKBiDAYBAAAqxmAQAACgYmQGX4CSHJYuE2UBtABzlOHQzEabTFgkl0Usye/kfiw9JZ+DjIpOn52dmbbmGaP8i/avpGipbkczHdE60XnQY9J9R8eo241yQHr99dpH/dV9lxSHLjlGpf2N+q/buezH2yk6/XKIntnc+yO6X9pcz5Jcai4LFz0TmqcryXjrOlH+r806+tne6ttumd3VuWk/6Zya9rTj3yd6HvQY9R2akn9vRRlvzQxubNl2Z+/YrbPctO+tZv5/23Ue/NSt09u376BFP8jyHdpjmnxqz//xU3+/nJ7KO0i2u9r1+1l1Ln+HppRS6st92DzOrqPXXt/VmiFMyV/XXA71eZ47vhkEAACoGINBAACAijEYBAAAqBiZwa9I7t/uS+pWRbk3zWZppiPKIup2ou1qxqGkZlauPp1m/75sO0q3k8tfpuT7H+X0dBnN5EVZxJL+6vnUvGVUP0qPoaRemu4nygFtbtpfWS+5JrmcYfRZSR5QjynKcz27ftsambg60bXXTKle67Z5z9x9F2X7cvdhSc3DqJ6lvgvaHFPJM6z6aeQ+29j8vWlvjf/WtDudD9w6047NGZZkKUvqDGot0/39fdO+deuWW2dz22636d437eXFf3HrdE/+0X4w8td+/Jm9Jg+f/rVpH57a/aSU0un4qd3P1PZ//eCf3Dr9t/PXvrtu+7e+/rFdwEez3f2h57ukfmR077atz8o3gwAAABVjMAgAAFAxBoMAAAAVYzAIAABQMSaQXIHcD5SnVFa4V5UULdV9nZ/b4HAUoC7pr36modSSYtYaWo4mZJQEs7UYasmPxutn0fnX/mqoOgrijsfjS/uSkg9i6370eEr6kpKfIKLL6OShqC8l4WI9d3pPpeQnEWj/o/Ot56pkcgJePtE75SrkJlyUvCtyxfJT8vddtF99tvSZKJm0VnKetjsygWEwdsus7dln6+7g3+1/P/k7t86Dzs9NW/sfvYv1mKOi0zohbW9vz/bt7l23ji6j5keP3Gdnj/+DaR9/6ieDPDp/aNr35z8x7dO5Lc6dUkrjuT2/g+Zz09bJOSmltPn5P5v2aj+4rgN7PwzkVbx+5t/5Z+nyiZHRfamfRff3s/cdRacBAABQhMEgAABAxRgMAgAAVIzM4BUoKbqa+3H0qMCuZlCiPFWbH6rWz0oKkGr/SjKD2t+o/yW5wlzx7ejc6TqadYn2pfmL6IfCSzIYuQLMUZZIc4QlOc5chjBapyQ7VPJj6CX3r9K8S3SMuH70/ijJykXXXu87fY5KnnO9x6K+6PNYkl3VZ6skA677Dgux922h4bX+790y/Vv2mPq78j68+I1bp3NxeS685LmPithrYeSdnR3TvnPnjltHC1Pre/bx1GcGD7u/Nu3PFp+6ZR7Nn1y63ZK86NnFif3vc1uUOqWUuk/tOsMdt0hqkuRQ5VU8Sq+5dU5W72X7mxPd388+J2QGAQAAUITBIAAAQMUYDAIAAFSMzOBXJJePKslwRJkZzQRofqckyxUto59pFmc2m2X7UpId0mWi7eZyblE9Ju3LdDrNblePOcpw6DpRzUDdjraje6Ekx5Sr5VeSqSrJW5YskzumKKtSci/i+iupjxYpyV7n1inJ8pXklPWz3HMU0WWivi0aW8NzvnzDb6hna+x1+7YvG5u+L72lfU9p5jHKF+dqK6bk33e5drQdfa/OFj5LPp7b8zKd+2U011mSGdR30PJCsn4rny3vbdl7rBPcys2Z/H08kjq9yWYTS5RkqqNr1PY9yzeDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFAxJpC8JKKwtAaQSwqoloRHS8L+Gr4tCV0rXSaaHKJKJoOUFHMtKdidK1gbhaFzE3ZSyh93FGzWfUdh87OzM9PWY4p+WF77UnJP6b6ja6LnpmS7uJn0fomeCb2HSibD6TrROydXDL+kuHVJUXXdbvQu04LM+gxE+5mt7MSCi+X33TLN/HO7nR17Xtb3/XbfPP+xac/7n5l2v+/fL7v926b9Wv+HbplXu6+b9vbKnpfzczvxIyV/f2gx/9PTU7eObieaAJj7UYPoPaufDVe2IPZGzxfwHrxi+99Z+fO9emrvl+PlN0z7vPOOW0fvB53AE91jeozRM/HsMTZNUzSpKiW+GQQAAKgag0EAAICKMRgEAACoGJnBr0ibQpCl/9b/rJIfJNdsQpSryWXAohyZ5hlKisbmchPRvl3uI/hBdc3PRZlBV4BU9hPlX/S4wx+fl2W0v9F11RxNybkr2W6bYrkl60TnE3VqU2w+en/kCplHmdhcfjh672reteS50XaUR9O+lOSqZ43dzsUqyDafSZH9PclS3vH7eXX1K/vBhX1Hbm364sr7t2wm+fa9X7tl9nZsfrEz+79M++Dgd24dvdaa/zs8PHTraI4wehfrdjRjF117l4Vf2fYy7bp1Zo9sX+ZnbpE0nf+DaR/3fmba0d/Y3N/qkh92iLb77P1c8nfkC3wzCAAAUDEGgwAAABVjMAgAAFAxBoMAAAAVYwLJS6wkLKrh3DYFpaMwty6jEz2idaKJHM8qKXAchX51GS3uGgXLc2H0lHxgV4+5pJh1FD7Xz3TfUTHrksk3uh09xqh4q8rdLymVHSPwPEqKqqs2heOjws5Kn5voXabvBt1P9K7LvXujZ1r7Mlv42QmTA7vM6A07ya637p/h4du2/2sru87Wrv/Tv33HnrvhtlskDYYykfDgn+x2T+xEipRSejy3BZeXU/v+Ozg+cOuUTCDJFZkumTQ4Wdl9Hy7ecOucPfxb056t/Ht23rMTZy6W+QLYen/r38fob6EeU3TvPvsMNE1T/AMAfDMIAABQMQaDAAAAFWMwCAAAUDEyg9dIVMRUPyvJ4mh+Icoz5PZTkjPUbFxUUFoLh0Z90X2XZOU0v1NyXkoKdJb8YL3mljTjGF3HkuxkmwLSqs06wPOIcnttClPrMxG9G3IF9EsK6kfvBn3+dD9R7lfX0Vxh9M5075PFkVvmYnJ5djzMPK7Za7A+sv0dbvr+lxTJXnTtMfb3bZav1/mvbp3tp/YdeTa27/yjI//+Pjk5Me3xeOyW0b8duQxhSv4azaXo93j1nlunJLu/mMl2Zd/R+zx3H0bPUUnm+9kMfdM04bmL8M0gAABAxRgMAgAAVIzBIAAAQMXIDL7ENB8QZQhytbiiTIEqWaZNzcPJZHLpNkr3nasZGGVmVJSH0cxGm1pokVw9QM26RMsAL6vc8xc90/rslzyzJevoZyW1/XJ1QL9svdx/z+UKS951s+Rr7h1P/860t35ja9pt/Nhvx9eFzddj9O8/f4wXc5v/m3fs35vFps+CXjT278D4sc0ZLo99ndjxuc25RdnsXGYwen/rddNlSv5GldxTukxJ/Uv9exTdL5pDzeVdS3LwX+CbQQAAgIoxGAQAAKgYg0EAAICKMRgEAACoGBNIrpGSMKiGmKPQtQZVS8KtJUFbnQSh60R90ZB1VIxWg8Ha32eLbF7WP6XnqmQSR0kh3FxB3bYTU4CXgZ+ckJ94VRKOzxWMjiaB6TNc8tznJo6l5N8pUcF8lTsPJRMPpslPLnu6+KVpbxz/B9Pefvgbt07/NdvfweDyosgp+eta8o5vmssnMKaU0vihPaYHn9427eOzT90651M7ySSaQJL7e1NyL5RMZNL7pc2PNER90e3qMkVFwIO/Wc9eAyaQAAAAoAiDQQAAgIoxGAQAAKgYmcGXmGYgotxELmcTZQZKfjQ+l6WI+pLLQEQ5IT3GqC+andDtROvovqNCzyVFvZXuO1pHP9NcZJQ5ifoHvIxyWeCSd05J0fpcJiylOKP2rCh3petE7w99RnU7Jc+9ivJdJUWEz5e2aPPR4gPT3vr9N9w63fnntv3tfKF+3XeUk8wV1J+f+WM8+sCey8/H9niOL47cOnr+o3fmiyjUH92XPifp7+9c3jLqvy5Tsh9dJrqOz96rTdMUZRxT4ptBAACAqjEYBAAAqBiDQQAAgIqRGbzmSn6YPSfKqbyIWnhRxuMqch+lmQilx3hVx6zHFOUrgetKn5OSbJ8qqblXkm3WrFauxme03ZJsVkmdRO1Lrh5jpKRG49HyoWkPJptuncHn9p3TGdpjXL2Wz1+GmcHGHsP0oT1PJ/f9eTk8/55pP7z4V9MuyXyX3C9t7sOS/LluJ7r2bWrL5uoXlvxdi67Rs+eBOoMAAAAowmAQAACgYgwGAQAAKsZgEAAAoGJMIAEAtNZm4lUUbM+F8KN1dFJGblJBSn4CQBTC12LQukw0iSBX8D+aEFBS6Fnpdsa9B26ZJ+Pvm/bi9/Y8TB586tYZbti+bL8dTPg7su3JU3uMn5+/4tY5XfzUtOdL2/+SiYVtfzxB6fku+aEB/dGA6H7XSYLal+gYc+uU/BhEVHT92f4xgQQAAABFGAwCAABUjMEgAABAxcgMAgCuTEmerk3OMFpH83NtCl6XFJ3W7fb7/k+n5s+0b5PJxK2zu7tr2iUFjbW/s+SL2h8170pfbpn22ek33TqDyci0N499fnGZbJZynsam/WT5G7eOnkvNuZXkAaPMnZ6XXNHyaDslOcPcfqPtah6w5McVcvdPtJ3oGJ/NODZNU3yMfDMIAABQMQaDAAAAFWMwCAAAUDEGgwAAABVjAgkA4IXSiRFRsd+rCvM/ryjcr5MRtPBwVOw3VwA7mnSiSiZT6OSEaNKJK3idHpv2WTp063Qb2//Owm83p2RyRckkH10m2q4uo+e/pMi3tqNzqctE29X7QZfRa5ZSWTHrXF9yy1B0GgAAAEUYDAIAAFSMwSAAAEDFyAwCAF6oqyg6/aJE+cXRyBZgdhm8IDemuTBdJsoMahZue3vbLTMY2OLP2pcoTxf177JtpOQzdyVyGbxoXyXFoUuKTue2G9FjLMnU5Yp+R9vVax31reTc5fajucOU7LkiMwgAAIAiDAYBAAAqxmAQAACgYmQGAQAvVJt8VwnN+5Xk0VS0jGbuNDcW9T+qUZfbj2bhovqFmj8ryb1p/9uclyhDmLuOJXX6riJnGC1TQo9Jr2uUTczdCyn5+1DPQ5Th1P4Ph8NsX0qO+dn7pWma4lqcfDMIAABQMQaDAAAAFWMwCAAAUDEGgwAAABVjAgkA4MpEIffSEPufuq82kwqiyQnT6dS0deJBNLlCt6MTP6JzoOvofqPtKC1KHW1XixNHfdFzl9tvJDr/2hfdd9QXPb+5yTlftu/cMjpJo+S8RJN8cuc3mgySExVDLyne/uy+KToNAACAIgwGAQAAKsZgEAAAoGJkBgEAXzvNQ2m7JI92VTQvt76+btolBYFz+bSU/DHOZjO3TK6w9ng8duuMRiPTLilUrTm3KKenfdHtllyPkpxnSTHrkvsjt92SLGtJdlJzhCX5S913VJg615dcZvB58M0gAABAxRgMAgAAVIzBIAAAQMXIDAIArkxUH02zZSX5qKuqLdeGZrGi2nJKc4WTycS0o+MZDofZ7ep2NHsYZRFz2b62tSBztRRLrkcuG1qyTvSZ9i3K0+l9p3Udo3Og5zI6Rv1Mz7feGyn5fKj2raTOYMlzVIpvBgEAACrGYBAAAKBiDAYBAAAqxmAQAACgYkwgAQBcmShgXzJJQJVMesgVOS4pnBwto5MydAJJFO7XyQfa37W1NbeOTsCIJqq0KZSsk070XJYYDAbuMz1XbQoct5kYFK2TmzCik0NS8te1ZNKGLqPnNlpvc3Pz0v2m5K9JybnU83KVRdf5ZhAAAKBiDAYBAAAqxmAQAACgYmQGAQBXpqQob8l62tZ8XUo+19am6HGb3FWU79IiwpoJi3JvmmuL+lJS9FjpvnLntnS7mnvU81CSpbwqui/dT1SQWTOZmuWLcp16TaLrqPvSeyE6t9oXXSY6by/qXKbEN4MAAABVYzAIAABQMQaDAAAAFWMwCAAAUDEmkAAArkzJ5ISoCLIG83OTICIa9o/W0X1HkzZK9pXbt+4nKjysn0UTMFTJpI2ckvMS9ff8/Ny0t7e3L+1b276UXEf9TItBR/3PFaqOCkrrRI/ofskVvI4KeLehk6iiySzPnpemacLzEOGbQQAAgIoxGAQAAKhY638mbvM1OgA8j5v+nrnpx/eFkjp3X9U6bbZbIrfdNv1vu93cb9iW1FYs+efzq/ht3Da/OR0t0+aflq/qfrmK7Zb89+e9h7743yXrtR4Mnp6etl0VAIqcnp6m3d3dr7sbL0wt79GSLNmLGGh8lbT/UdHjnJI8morO7cnJyaXtq/Kitvt10WLRbWlOrzS397zbLVXyHu00Lf9v0Wq1Svfv30/b29thiBEA2mqaJp2enqbXX389nGxwU/AeBfCiPM97tPVgEAAAANffzf2/3AAAAMhiMAgAAFAxBoMAAAAVYzAIAABQMQaDAAAAFWMwCAAAUDEGgwAAABVjMAgAAFAxBoMAAAAVYzAIAABQMQaDAAAAFWMwCAAAULH/H0aogS4hUNGWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "offset = np.random.randint(60)\n",
    "\n",
    "for n, (image, mask) in aug_dataset.unbatch().take(4).enumerate(start=offset).as_numpy_iterator():\n",
    "    \n",
    "    plt.subplot(2,2,n-offset+1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.imshow(mask, cmap='gnuplot', alpha=0.2)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Build Augmented Data of Set Size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_ds_aug = aug_dataset.unbatch().shuffle(1).take(10000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(start_neurons = 16, kernel_size=(3, 3), dropout_prob=0.2):\n",
    "    \n",
    "    inputs = keras.Input(shape=img_size + (1,))\n",
    "    \n",
    "    c1 = layers.Conv2D(start_neurons, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(start_neurons, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    p1 = layers.Dropout(dropout_prob)(p1)    \n",
    "\n",
    "    c2 = layers.Conv2D(start_neurons*2, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(start_neurons*2, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    p2 = layers.Dropout(dropout_prob)(p2)\n",
    "\n",
    "    c3 = layers.Conv2D(start_neurons*4, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    #c3 = layers.Dropout(dropout_prob)(c3)\n",
    "    c3 = layers.Conv2D(start_neurons*4, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "    p3 = layers.Dropout(dropout_prob)(p3)\n",
    "\n",
    "    c4 = layers.Conv2D(start_neurons*8, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    #c4 = layers.Dropout(dropout_prob)(c4)\n",
    "    c4 = layers.Conv2D(start_neurons*8, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "    p4 = layers.Dropout(dropout_prob)(p4)\n",
    "\n",
    "    c5 = layers.Conv2D(start_neurons*16, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    #c5 = layers.Dropout(0.3)(c5)\n",
    "    c5 = layers.Conv2D(start_neurons*16, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    u6 = layers.Conv2DTranspose(start_neurons*8, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    u6 = layers.Dropout(dropout_prob)(u6)\n",
    "    c6 = layers.Conv2D(start_neurons*8, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    #c6 = layers.Dropout(dropout_prob)(c6)\n",
    "    c6 = layers.Conv2D(start_neurons*8, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(start_neurons*4, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    u7 = layers.Dropout(dropout_prob)(u7)\n",
    "    c7 = layers.Conv2D(start_neurons*4, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    #c7 = layers.Dropout(dropout_prob)(c7)\n",
    "    c7 = layers.Conv2D(start_neurons*4, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(start_neurons*2, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    u8 = layers.Dropout(dropout_prob)(u8)\n",
    "    c8 = layers.Conv2D(start_neurons*2, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    #c8 = layers.Dropout(0.1)(c8)\n",
    "    c8 = layers.Conv2D(start_neurons*2, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(start_neurons, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    u9 = layers.Dropout(dropout_prob)(u9)\n",
    "    c9 = layers.Conv2D(start_neurons, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    #c9 = layers.Dropout(0.1)(c9)\n",
    "    c9 = layers.Conv2D(start_neurons, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "    return keras.Model(inputs, outputs, name='U-Net')\n",
    "\n",
    "#get_unet(8).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs: 1\n",
      "Thu Apr  6 11:57:19 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   36C    P0    32W / 250W |  15781MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     29385      C                                   15779MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Ensure tensorflow is using GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if(len(physical_devices) > 0):\n",
    "    print(f\"Number of GPUs: {len(physical_devices)}\")\n",
    "else:\n",
    "    print(\"No GPU detected... Running on CPU\")\n",
    "    \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "model = get_unet()\n",
    "\n",
    "epochs = 1000 # max number of epochs for training\n",
    "#steps_per_epoch = 100 # number of batches processed for each epoch\n",
    "\n",
    "\"\"\"\n",
    "Augmentation factor = how many times each image is seen per training epoch\n",
    "                    = steps_per_epoch*batch_size/num_training_images\n",
    "    e.g. 1000*16/68 = 235.3\n",
    "\"\"\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(time.strftime('model_checkpoints/%Y%m%d_%H_%M_%S/'))\n",
    "#log_dir = os.path.join('logs/fit/', checkpoint_dir, time.strftime('%Y%m%d_%H_%M_%S'))\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(os.path.join(checkpoint_dir, '{epoch:02d}-{val_loss:.4f}.keras'), save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=0, restore_best_weights=True),\n",
    "    #keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.BinaryIoU(name='Binary IoU', threshold=0.5),\n",
    "    #keras.metrics.BinaryCrossentropy(name='Binary Cross-Entropy'),\n",
    "    keras.metrics.BinaryAccuracy(name='Binary Accuracy', threshold=0.5),\n",
    "    #keras.metrics.Precision(name='Precision', thresholds=0.5),\n",
    "    #keras.metrics.Recall(name='Recall', thresholds=0.5)\n",
    "]\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "#model_history = model.fit(train_ds_aug, epochs=epochs, validation_data=val_ds, verbose=1, callbacks=callbacks)\n",
    "\n",
    "# Save history as csv\n",
    "#hist_csv_file = os.path.join(checkpoint_dir, 'history.csv')\n",
    "#with open(hist_csv_file, mode='w') as f:  \n",
    "    #hist_df = pd.DataFrame(model_history.history)\n",
    "    #hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    # hyper parameters\n",
    "    hp_learning_rate = hp.Float(\"learning_rate\", min_value=0.00001, max_value=0.01, sampling=\"log\")\n",
    "    hp_kernel_size = hp.Choice('kernel_size', values=[3, 5])\n",
    "    hp_num_images = hp.Int(\"num_images\", min_value=340, max_value=13600, sampling='log')\n",
    "    \n",
    "    model = get_unet(16, (hp_kernel_size, hp_kernel_size), 0.2)\n",
    "\n",
    "    train_ds_aug = aug_dataset.unbatch().take(hp_num_images).shuffle(1).batch(16)\n",
    "    \n",
    "    #checkpoint_dir = os.path.dirname(time.strftime('model_checkpoints/%Y%m%d_%H_%M_%S/'))\n",
    "\n",
    "\n",
    "    metrics = [\n",
    "        keras.metrics.BinaryIoU(name='BinaryIoU', threshold=0.5),\n",
    "        keras.metrics.BinaryAccuracy(name='Binary Accuracy', threshold=0.5),\n",
    "    ]\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.BayesianOptimization(build_model,\n",
    "                     objective=[kt.Objective(\"val_BinaryIoU\", direction=\"max\"), kt.Objective(\"val_loss\", direction='min'), ],\n",
    "                     max_trials=20,\n",
    "                     directory='tuning',\n",
    "                     project_name='spiral_segmentation_2', overwrite=False)\n",
    "\n",
    "callbacks = [\n",
    "    #keras.callbacks.ModelCheckpoint(os.path.join(checkpoint_dir, '{epoch:02d}-{val_loss:.4f}.keras'), save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, min_delta=0, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "#tuner.search_space_summary()\n",
    "tuner.search(train_ds_aug, epochs=200, validation_data=val_ds, verbose=1, callbacks=callbacks)\n",
    "\n",
    "tuner.results_summary()\n",
    "# Get the optimal hyperparameters\n",
    "#best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "125 * (math.log(125, 3) ** 2) * 0.2 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] Test Model and Assess Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_ds)\n",
    "\n",
    "plt.figure(figsize=(12,60))\n",
    "\n",
    "for n, (gt_img, gt_mask) in enumerate(test_ds.unbatch().take(15)):\n",
    "    \n",
    "    plt.subplot(15,3,3*n+1)\n",
    "    plt.imshow(gt_img, cmap='gray', alpha=1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(15,3,3*n+2)\n",
    "    plt.imshow(gt_mask, cmap='gnuplot', alpha=1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(15,3,3*n+3)\n",
    "    plt.imshow(test_preds[n], cmap='gnuplot', alpha=1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "os.mkdir(os.path.join(checkpoint_dir, 'analysis'))\n",
    "plt.savefig(os.path.join(checkpoint_dir, 'analysis', 'test_predictions.png'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "epochs = range(len(model_history.history[\"loss\"]))\n",
    "loss = model_history.history[\"loss\"]\n",
    "val_loss = model_history.historyfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "\n",
    "metric_epochs = range(len(model_history.history['loss']))\n",
    "metric_loss = model_history.history['loss']\n",
    "metric_val_loss = model_history.history['val_loss']\n",
    "\n",
    "ax[0].plot(metric_epochs[5:], metric_loss[5:], 'r', label='Training')\n",
    "ax[0].plot(metric_epochs[5:], metric_val_loss[5:], 'bo', label='Validation')\n",
    "ax[0].set_title('Training and Validation Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss Value')\n",
    "ax[0].legend()\n",
    "\n",
    "metric_iou = model_history.history['Binary IoU']\n",
    "metric_val_iou = model_history.history['val_Binary IoU']\n",
    "\n",
    "ax[1].plot(metric_epochs, metric_iou, 'r', label='Training')\n",
    "ax[1].plot(metric_epochs, metric_val_iou, 'bo', label='Validation')\n",
    "ax[1].set_title('Training and Validation IoU')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('IoU Value')\n",
    "ax[1].legend()\n",
    "plt.savefig(os.path.join(checkpoint_dir, 'analysis', 'metrics.png'))\n",
    "plt.show()[\"val_loss\"]\n",
    "\n",
    "ax[0].plot(epochs, loss, \"r\", label=\"Training\")\n",
    "ax[0].plot(epochs, val_loss, \"bo\", label=\"Validation\")\n",
    "ax[0].set_title(\"Training and Validation Loss\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"Loss Value\")\n",
    "ax[0].legend()\n",
    "\n",
    "iou = model_history.history[\"Binary IoU\"]\n",
    "val_iou = model_history.history[\"val_Binary IoU\"]\n",
    "\n",
    "ax[1].plot(epochs, iou, \"r\", label=\"Training\")\n",
    "ax[1].plot(epochs, val_iou, \"bo\", label=\"Validation\")\n",
    "ax[1].set_title(\"Training and Validation IoU\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"IoU Value\")\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation of Spiral Galaxies\n",
    "\n",
    "This notebook provides a detailed insight into the process that goes into the segmentation of spiral arms from images of spiral galaxies. This notebook accompanies the final year research project I completed for my Masters Degree in Professional Engineering (Software) at University of WA. The dataset used for this notebook is adapted from images retrieved from the 2nd public data release from the HSC data archive system, which is operated by Subaru Telescope and Astronomy Data Center at National Astronomical Observatory of Japan and classification of spiral galaxies from this dataset was achieved by [Tadaki et al.](https://arxiv.org/pdf/2006.13544.pdf) and all image content is a product of their work. You can register to access the HSC Data [here](https://hsc-release.mtk.nao.ac.jp/doc/index.php/data-access__pdr3/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Install Dependencies\n",
    "\n",
    "Here we will run the imports for packages that are used commonly throughout the notebook. Any other required packages will be imported within the code cell that they are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip list\n",
    "#!pip install --upgrade --user tensorflow==2.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Data Pre-Processing\n",
    "\n",
    "This section covers the functionality used to process the data prior to it being used in training the segmentation model. These functions take the images from the dataset (in the format of `.jpg` and `.tif` files) to a data format that is usable by the Tensorflow Keras API. To achieve a concise pipeline, a Keras Sequence class is used to load and vectorize the data before training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Location of Data and Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '../data/images/'\n",
    "masks_dir = '../data/masks/'\n",
    "img_size = (64, 64)\n",
    "\n",
    "val_split = 16 # % of total dataset to be used for validation\n",
    "test_split = 16 # % of total dataset to be used for testing\n",
    "val_batch_size = 1 # batch size per step\n",
    "test_batch_size = 1\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Split Into Subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_ds = tf.keras.utils.image_dataset_from_directory(images_dir, \n",
    "                                         labels=None, \n",
    "                                         color_mode='grayscale', \n",
    "                                         shuffle=False, \n",
    "                                         image_size=img_size, \n",
    "                                         batch_size=None)\n",
    "\n",
    "masks_ds = tf.keras.utils.image_dataset_from_directory(masks_dir, \n",
    "                                        labels=None, \n",
    "                                        color_mode='grayscale', \n",
    "                                        shuffle=False, \n",
    "                                        image_size=img_size, \n",
    "                                        batch_size=None)\n",
    "\n",
    "dataset = tf.data.Dataset.zip((images_ds, masks_ds))\n",
    "\n",
    "train_ds, test_ds = tf.keras.utils.split_dataset(dataset, \n",
    "                                 right_size=test_split/100, \n",
    "                                 shuffle=False)\n",
    "\n",
    "train_ds, val_ds = tf.keras.utils.split_dataset(train_ds, \n",
    "                                 right_size=val_split/(100-test_split), \n",
    "                                 shuffle=False)\n",
    "\n",
    "val_ds = val_ds.batch(val_batch_size)\n",
    "test_ds = test_ds.batch(test_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Data Augmentation Pipeline\n",
    "\n",
    "Using in-built Keras preprocessing sequential layers, here we build a pipeline that can be used to augment the training images from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image, mask):\n",
    "    \n",
    "    aug_model = keras.Sequential(\n",
    "        layers = [\n",
    "            layers.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
    "            layers.RandomRotation((-0.25, 0.25), fill_mode=\"constant\", interpolation='nearest', fill_value=0),\n",
    "            layers.RandomTranslation(0.2,0.2, fill_mode=\"constant\", interpolation='nearest', fill_value=0),\n",
    "            layers.RandomZoom((-0.01, 0.01),(-0.01, 0.01),interpolation='nearest'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    image_mask = tf.concat([image, mask], -1)\n",
    "    image_mask = aug_model(image_mask)\n",
    "    \n",
    "    image = image_mask[:,:,:,0]\n",
    "    mask = image_mask[:,:,:,1]\n",
    "    \n",
    "    image = tf.reshape(image, [-1, img_size[0], img_size[1], 1])\n",
    "    mask = tf.reshape(mask, [-1, img_size[0], img_size[1], 1])\n",
    "    \n",
    "    return image, mask\n",
    "\n",
    "aug_dataset = (\n",
    "\ttrain_ds\n",
    "    .repeat()\n",
    "    .batch(batch_size)\n",
    "    .map(lambda img,msk: augment(img, msk))\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate Data is Loaded Correctly\n",
    "\n",
    "The following plot should correctly display 4 examples from the augmented dataset of overlayed image segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "offset = np.random.randint(60)\n",
    "\n",
    "for n, (image, mask) in aug_dataset.unbatch().take(4).enumerate(start=offset).as_numpy_iterator():\n",
    "    \n",
    "    plt.subplot(2,2,n-offset+1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.imshow(mask, cmap='gnuplot', alpha=0.2)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Build Augmented Data of Set Size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_ds_aug = aug_dataset.unbatch().shuffle(1).take(10000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(start_neurons = 16, kernel_size=(3, 3), dropout_prob=0.2):\n",
    "    \n",
    "    inputs = keras.Input(shape=img_size + (1,))\n",
    "    \n",
    "    c1 = layers.Conv2D(start_neurons, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(start_neurons, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
    "    p1 = layers.Dropout(dropout_prob)(p1)    \n",
    "\n",
    "    c2 = layers.Conv2D(start_neurons*2, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(start_neurons*2, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
    "    p2 = layers.Dropout(dropout_prob)(p2)\n",
    "\n",
    "    c3 = layers.Conv2D(start_neurons*4, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    #c3 = layers.Dropout(dropout_prob)(c3)\n",
    "    c3 = layers.Conv2D(start_neurons*4, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
    "    p3 = layers.Dropout(dropout_prob)(p3)\n",
    "\n",
    "    c4 = layers.Conv2D(start_neurons*8, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    #c4 = layers.Dropout(dropout_prob)(c4)\n",
    "    c4 = layers.Conv2D(start_neurons*8, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = layers.MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "    p4 = layers.Dropout(dropout_prob)(p4)\n",
    "\n",
    "    c5 = layers.Conv2D(start_neurons*16, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    #c5 = layers.Dropout(0.3)(c5)\n",
    "    c5 = layers.Conv2D(start_neurons*16, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "\n",
    "    u6 = layers.Conv2DTranspose(start_neurons*8, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = layers.concatenate([u6, c4])\n",
    "    u6 = layers.Dropout(dropout_prob)(u6)\n",
    "    c6 = layers.Conv2D(start_neurons*8, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    #c6 = layers.Dropout(dropout_prob)(c6)\n",
    "    c6 = layers.Conv2D(start_neurons*8, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "\n",
    "    u7 = layers.Conv2DTranspose(start_neurons*4, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = layers.concatenate([u7, c3])\n",
    "    u7 = layers.Dropout(dropout_prob)(u7)\n",
    "    c7 = layers.Conv2D(start_neurons*4, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    #c7 = layers.Dropout(dropout_prob)(c7)\n",
    "    c7 = layers.Conv2D(start_neurons*4, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "\n",
    "    u8 = layers.Conv2DTranspose(start_neurons*2, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = layers.concatenate([u8, c2])\n",
    "    u8 = layers.Dropout(dropout_prob)(u8)\n",
    "    c8 = layers.Conv2D(start_neurons*2, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    #c8 = layers.Dropout(0.1)(c8)\n",
    "    c8 = layers.Conv2D(start_neurons*2, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "\n",
    "    u9 = layers.Conv2DTranspose(start_neurons, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = layers.concatenate([u9, c1])\n",
    "    u9 = layers.Dropout(dropout_prob)(u9)\n",
    "    c9 = layers.Conv2D(start_neurons, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    #c9 = layers.Dropout(0.1)(c9)\n",
    "    c9 = layers.Conv2D(start_neurons, kernel_size, activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    \n",
    "    return keras.Model(inputs, outputs, name='U-Net')\n",
    "\n",
    "#get_unet(8).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure tensorflow is using GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if(len(physical_devices) > 0):\n",
    "    print(f\"Number of GPUs: {len(physical_devices)}\")\n",
    "else:\n",
    "    print(\"No GPU detected... Running on CPU\")\n",
    "    \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "model = get_unet()\n",
    "\n",
    "epochs = 1000 # max number of epochs for training\n",
    "#steps_per_epoch = 100 # number of batches processed for each epoch\n",
    "\n",
    "\"\"\"\n",
    "Augmentation factor = how many times each image is seen per training epoch\n",
    "                    = steps_per_epoch*batch_size/num_training_images\n",
    "    e.g. 1000*16/68 = 235.3\n",
    "\"\"\"\n",
    "\n",
    "checkpoint_dir = os.path.dirname(time.strftime('model_checkpoints/%Y%m%d_%H_%M_%S/'))\n",
    "#log_dir = os.path.join('logs/fit/', checkpoint_dir, time.strftime('%Y%m%d_%H_%M_%S'))\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(os.path.join(checkpoint_dir, '{epoch:02d}-{val_loss:.4f}.keras'), save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=0, restore_best_weights=True),\n",
    "    #keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.BinaryIoU(name='Binary IoU', threshold=0.5),\n",
    "    #keras.metrics.BinaryCrossentropy(name='Binary Cross-Entropy'),\n",
    "    keras.metrics.BinaryAccuracy(name='Binary Accuracy', threshold=0.5),\n",
    "    #keras.metrics.Precision(name='Precision', thresholds=0.5),\n",
    "    #keras.metrics.Recall(name='Recall', thresholds=0.5)\n",
    "]\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=metrics)\n",
    "#model_history = model.fit(train_ds_aug, epochs=epochs, validation_data=val_ds, verbose=1, callbacks=callbacks)\n",
    "\n",
    "# Save history as csv\n",
    "#hist_csv_file = os.path.join(checkpoint_dir, 'history.csv')\n",
    "#with open(hist_csv_file, mode='w') as f:  \n",
    "    #hist_df = pd.DataFrame(model_history.history)\n",
    "    #hist_df.to_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import keras_tuner as kt\n",
    "from typing import Callable\n",
    "\n",
    "def binary_tversky_coef(y_true: tf.Tensor, y_pred: tf.Tensor, beta: float, smooth: float = 1.) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Tversky coefficient is a generalization of the Dice's coefficient. It adds an extra weight (β) to false positives\n",
    "    and false negatives:\n",
    "        TC(p, p̂) = p*p̂/[p*p̂ + β*(1-p)*p̂ + (1-β)*p*(1-p̂)]\n",
    "    When β=1/2, Tversky coefficient is equal to the Dice's coefficient:\n",
    "        TL(p, p̂) = p*p̂/[p*p̂ + (1/2)*(1-p)*p̂ + (1-(1/2))*p*(1-p̂)]\n",
    "        = p*p̂/[p*p̂ + (1/2)*p̂ - (1/2)*p*p̂ + (1/2)*p*(1-p̂)]\n",
    "        = p*p̂/[p*p̂ + (1/2)*p̂ - (1/2)*p*p̂ + (1/2)*p - (1/2)*p*p̂)]\n",
    "        = p*p̂/[p*p - p*p̂̂ + (1/2)*p̂ + (1/2)*p]\n",
    "        = p*p̂/[(1/2)*p̂ + (1/2)*p]\n",
    "        = p*p̂/[(1/2)*(p̂+p)]\n",
    "        = 2*p*p̂/(p̂+p)\n",
    "    :param y_true: True masks (tf.Tensor, shape=(<BATCH_SIZE>, <IMAGE_HEIGHT>, <IMAGE_WIDTH>, 1))\n",
    "    :param y_pred: Predicted masks (tf.Tensor, shape=(<BATCH_SIZE>, <IMAGE_HEIGHT>, <IMAGE_WIDTH>, 1))\n",
    "    :param beta: Weight coefficient (float)\n",
    "    :param smooth: Smoothing factor (float, default = 1.)\n",
    "    :return: Tversky coefficient (tf.Tensor, shape=(<BATCH_SIZE>, <IMAGE_HEIGHT>, <IMAGE_WIDTH>))\n",
    "    \"\"\"\n",
    "    axis_to_reduce = range(1, keras.backend.ndim(y_pred))  # All axis but first (batch)\n",
    "    numerator = keras.backend.sum(y_true * y_pred, axis=axis_to_reduce)  # p*p̂\n",
    "    denominator = y_true * y_pred + beta * (1 - y_true) * y_pred + (1 - beta) * y_true * (1 - y_pred)  # p*p̂ + β*(1-p)*p̂ + (1-β)*p*(1-p̂)\n",
    "    denominator = keras.backend.sum(denominator, axis=axis_to_reduce)\n",
    "\n",
    "    return (numerator + smooth) / (denominator + smooth)  # (p*p̂ + smooth)/[p*p̂ + β*(1-p)*p̂ + (1-β)*p*(1-p̂) + smooth]\n",
    "\n",
    "def binary_dice_coef_loss(smooth: float = 1.) -> Callable[[tf.Tensor, tf.Tensor], tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Dice coefficient loss:\n",
    "        DL(p, p̂) = 1 - (2*p*p̂+smooth)/(p+p̂+smooth)\n",
    "    Used as loss function for binary image segmentation with one-hot encoded masks.\n",
    "    :param smooth: Smoothing factor (float, default=1.)\n",
    "    :return: Dice coefficient loss function (Callable[[tf.Tensor, tf.Tensor], tf.Tensor])\n",
    "    \"\"\"\n",
    "    def loss(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the Dice loss (Tversky loss with β=0.5).\n",
    "        :param y_true: True masks (tf.Tensor, shape=(<BATCH_SIZE>, <IMAGE_HEIGHT>, <IMAGE_WIDTH>, 1))\n",
    "        :param y_pred: Predicted masks (tf.Tensor, shape=(<BATCH_SIZE>, <IMAGE_HEIGHT>, <IMAGE_WIDTH>, 1))\n",
    "        :return: Dice coefficient loss for each observation in batch (tf.Tensor, shape=(<BATCH_SIZE>,))\n",
    "        \"\"\"\n",
    "        return 1 - binary_tversky_coef(y_true=y_true, y_pred=y_pred, beta=0.5, smooth=smooth)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def binary_tversky_loss(beta: float) -> Callable[[tf.Tensor, tf.Tensor], tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Tversky loss:\n",
    "        TL(p, p̂) = 1 - p*p̂/[p*p̂ + β*(1-p)*p̂ + (1-β)*p*(1-p̂)]\n",
    "    Used as loss function for binary image segmentation with one-hot encoded masks.\n",
    "    :param beta: Weight coefficient (float)\n",
    "    :return: Tversky loss function (Callable[[tf.Tensor, tf.Tensor], tf.Tensor])\n",
    "    \"\"\"\n",
    "    def loss(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the Tversky loss.\n",
    "        :param y_true: True masks (tf.Tensor, shape=(<BATCH_SIZE>, <IMAGE_HEIGHT>, <IMAGE_WIDTH>, 1))\n",
    "        :param y_pred: Predicted masks (tf.Tensor, shape=(<BATCH_SIZE>, <IMAGE_HEIGHT>, <IMAGE_WIDTH>, 1))\n",
    "        :return: Tversky loss (tf.Tensor, shape=(<BATCH_SIZE>,))\n",
    "        \"\"\"\n",
    "        return 1-binary_tversky_coef(y_true, y_pred, beta=beta)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    epochs = 200 # max number of epochs for training\n",
    "    \n",
    "    # loss functions\n",
    "    loss_dict = {\n",
    "        'dice_loss': binary_dice_coef_loss(),\n",
    "        'tversky_loss': binary_tversky_loss(0.5),\n",
    "        'binary_focal_crossentropy': 'binary_focal_crossentropy',\n",
    "        'binary_crossentropy': 'binary_crossentropy'\n",
    "    }\n",
    "    \n",
    "    # hyper parameters\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "    hp_batch_size = hp.Choice('batch_size', values=[8, 16, 32, 64, 128])\n",
    "    hp_kernel_size = hp.Choice('kernel_size', values=[3, 5, 7])\n",
    "    hp_start_neurons = hp.Choice('start_neurons', values=[8, 16])\n",
    "    hp_dropout_prob = hp.Choice('dropout_prob', values=[0.1, 0.2, 0.3])\n",
    "    hp_loss = hp.Choice('loss', values=['binary_focal_crossentropy', 'binary_crossentropy', 'tversky_loss', 'dice_loss'])\n",
    "    \n",
    "    model = get_unet(hp_start_neurons, (hp_kernel_size, hp_kernel_size), hp_dropout_prob)\n",
    "\n",
    "    train_ds_aug = aug_dataset.unbatch().shuffle(1, seed=37).take(10000).batch(hp_batch_size)\n",
    "    \n",
    "    #checkpoint_dir = os.path.dirname(time.strftime('model_checkpoints/%Y%m%d_%H_%M_%S/'))\n",
    "\n",
    "\n",
    "    metrics = [\n",
    "        keras.metrics.BinaryIoU(name='Binary IoU', threshold=0.5),\n",
    "        keras.metrics.BinaryAccuracy(name='Binary Accuracy', threshold=0.5),\n",
    "    ]\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss_dict[hp_loss], metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective=kt.Objective(\"val_Binary IoU\", direction=\"max\"),\n",
    "                     max_epochs=200,\n",
    "                     factor=3,\n",
    "                     directory='tuning',\n",
    "                     project_name='spiral_segmentation', overwrite=False)\n",
    "\n",
    "callbacks = [\n",
    "    #keras.callbacks.ModelCheckpoint(os.path.join(checkpoint_dir, '{epoch:02d}-{val_loss:.4f}.keras'), save_best_only=True),\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=0, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "tuner.search(train_ds_aug, epochs=200, validation_data=val_ds, verbose=1, callbacks=callbacks)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "125 * (math.log(125, 3) ** 2) * 0.2 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] Test Model and Assess Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_ds)\n",
    "\n",
    "plt.figure(figsize=(12,60))\n",
    "\n",
    "for n, (gt_img, gt_mask) in enumerate(test_ds.unbatch().take(15)):\n",
    "    \n",
    "    plt.subplot(15,3,3*n+1)\n",
    "    plt.imshow(gt_img, cmap='gray', alpha=1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(15,3,3*n+2)\n",
    "    plt.imshow(gt_mask, cmap='gnuplot', alpha=1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "    plt.subplot(15,3,3*n+3)\n",
    "    plt.imshow(test_preds[n], cmap='gnuplot', alpha=1)\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    \n",
    "os.mkdir(os.path.join(checkpoint_dir, 'analysis'))\n",
    "plt.savefig(os.path.join(checkpoint_dir, 'analysis', 'test_predictions.png'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "\n",
    "epochs = range(len(model_history.history[\"loss\"]))\n",
    "loss = model_history.history[\"loss\"]\n",
    "val_loss = model_history.historyfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
    "\n",
    "metric_epochs = range(len(model_history.history['loss']))\n",
    "metric_loss = model_history.history['loss']\n",
    "metric_val_loss = model_history.history['val_loss']\n",
    "\n",
    "ax[0].plot(metric_epochs[5:], metric_loss[5:], 'r', label='Training')\n",
    "ax[0].plot(metric_epochs[5:], metric_val_loss[5:], 'bo', label='Validation')\n",
    "ax[0].set_title('Training and Validation Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss Value')\n",
    "ax[0].legend()\n",
    "\n",
    "metric_iou = model_history.history['Binary IoU']\n",
    "metric_val_iou = model_history.history['val_Binary IoU']\n",
    "\n",
    "ax[1].plot(metric_epochs, metric_iou, 'r', label='Training')\n",
    "ax[1].plot(metric_epochs, metric_val_iou, 'bo', label='Validation')\n",
    "ax[1].set_title('Training and Validation IoU')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('IoU Value')\n",
    "ax[1].legend()\n",
    "plt.savefig(os.path.join(checkpoint_dir, 'analysis', 'metrics.png'))\n",
    "plt.show()[\"val_loss\"]\n",
    "\n",
    "ax[0].plot(epochs, loss, \"r\", label=\"Training\")\n",
    "ax[0].plot(epochs, val_loss, \"bo\", label=\"Validation\")\n",
    "ax[0].set_title(\"Training and Validation Loss\")\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"Loss Value\")\n",
    "ax[0].legend()\n",
    "\n",
    "iou = model_history.history[\"Binary IoU\"]\n",
    "val_iou = model_history.history[\"val_Binary IoU\"]\n",
    "\n",
    "ax[1].plot(epochs, iou, \"r\", label=\"Training\")\n",
    "ax[1].plot(epochs, val_iou, \"bo\", label=\"Validation\")\n",
    "ax[1].set_title(\"Training and Validation IoU\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(\"IoU Value\")\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf (Local)",
   "language": "python",
   "name": "local-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
